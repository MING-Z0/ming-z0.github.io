<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CUDA开始的GPU编程 | MINGの部落格</title><meta name="author" content="Ming"><meta name="copyright" content="Ming"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="CUDA开始的GPU编程前置条件：  熟悉C&#x2F;C++编程、熟悉STL、函数模板等 Nvidia GTX900及以上显卡、CUDA 11及以上 CMake 3.18及以上  由于文本编辑器不持支CUDA代码块，文中CUDA代码将使用cpp代码块进行高亮显示，请注意区分。 在开始之前，我想提醒读者，这篇博客将以工程应用的思路为主，不会深入探讨CUDA的底层原理。我们关注实际的使用案例和实践技">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA开始的GPU编程">
<meta property="og:url" content="https://ming-z0.github.io/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/index.html">
<meta property="og:site_name" content="MINGの部落格">
<meta property="og:description" content="CUDA开始的GPU编程前置条件：  熟悉C&#x2F;C++编程、熟悉STL、函数模板等 Nvidia GTX900及以上显卡、CUDA 11及以上 CMake 3.18及以上  由于文本编辑器不持支CUDA代码块，文中CUDA代码将使用cpp代码块进行高亮显示，请注意区分。 在开始之前，我想提醒读者，这篇博客将以工程应用的思路为主，不会深入探讨CUDA的底层原理。我们关注实际的使用案例和实践技">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ming-z0.github.io/img/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2/6.jpg">
<meta property="article:published_time" content="2024-10-23T16:00:00.000Z">
<meta property="article:modified_time" content="2025-01-01T16:58:17.612Z">
<meta property="article:author" content="Ming">
<meta property="article:tag" content="CUDA">
<meta property="article:tag" content="GPU编程">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ming-z0.github.io/img/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2/6.jpg"><link rel="shortcut icon" href="/./img/%E5%9B%BE%E6%A0%87/favicon.png"><link rel="canonical" href="https://ming-z0.github.io/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.clarity.ms"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "i5biwbw9sk");</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":-1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: true
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CUDA开始的GPU编程',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-01-02 00:58:17'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (true) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./img/%E5%A4%B4%E5%83%8F.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 分析</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-user"></i><span> 我的</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 收藏</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1VB4y137ys/"><i class="fa-fw fas fa-heart"></i><span> ROS2理论与实践</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1if4y147hS/"><i class="fa-fw fas fa-heart"></i><span> 动手学深度学习</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://geek-logic.com/"><i class="fa-fw fas fa-heart"></i><span> Geek Logic</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://github.com/parallel101/cppguidebook"><i class="fa-fw fas fa-heart"></i><span> 小彭老师C++大典</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url('/./img/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2/6.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="MINGの部落格"><span class="site-name">MINGの部落格</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 分析</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-user"></i><span> 我的</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 收藏</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1VB4y137ys/"><i class="fa-fw fas fa-heart"></i><span> ROS2理论与实践</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1if4y147hS/"><i class="fa-fw fas fa-heart"></i><span> 动手学深度学习</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://geek-logic.com/"><i class="fa-fw fas fa-heart"></i><span> Geek Logic</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://github.com/parallel101/cppguidebook"><i class="fa-fw fas fa-heart"></i><span> 小彭老师C++大典</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CUDA开始的GPU编程</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-10-23T16:00:00.000Z" title="发表于 2024-10-24 00:00:00">2024-10-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-01-01T16:58:17.612Z" title="更新于 2025-01-02 00:58:17">2025-01-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/GPU%E7%BC%96%E7%A8%8B/">GPU编程</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">21.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>92分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CUDA开始的GPU编程"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="CUDA开始的GPU编程"><a href="#CUDA开始的GPU编程" class="headerlink" title="CUDA开始的GPU编程"></a>CUDA开始的GPU编程</h1><p>前置条件：</p>
<ul>
<li>熟悉C&#x2F;C++编程、熟悉STL、函数模板等</li>
<li>Nvidia GTX900及以上显卡、CUDA 11及以上</li>
<li>CMake 3.18及以上</li>
</ul>
<p><em>由于文本编辑器不持支CUDA代码块，文中CUDA代码将使用cpp代码块进行高亮显示，请注意区分。</em></p>
<p>在开始之前，我想提醒读者，这篇博客将以工程应用的思路为主，不会深入探讨CUDA的底层原理。我们关注实际的使用案例和实践技巧。未来，我会逐步更新更为详尽的内容，敬请期待！</p>
<h2 id="第0章：Hello-world-from-GPU"><a href="#第0章：Hello-world-from-GPU" class="headerlink" title="第0章：Hello, world from GPU!"></a>第0章：Hello, world from GPU!</h2><h3 id="CMake中启用CUDA支持"><a href="#CMake中启用CUDA支持" class="headerlink" title="CMake中启用CUDA支持"></a>CMake中启用CUDA支持</h3><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CMakeLists.txt</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_STANDARD <span class="number">17</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_BUILD_TYPE Release)</span><br><span class="line"></span><br><span class="line"><span class="keyword">project</span>(hellocuda LANGUAGES CXX CUDA)	<span class="comment"># 添加CUDA支持</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(main main.cu)	<span class="comment"># 添加.cu源文件</span></span><br></pre></td></tr></table></figure>

<p>最新版的 CMake（3.18 以上），只需在 LANGUAGES 后面加上 CUDA 即可启用。</p>
<p>然后在 add_executable 里直接加你的 .cu 文件，和 .cpp 一样。</p>
<h3 id="CUDA编译器兼容C-17"><a href="#CUDA编译器兼容C-17" class="headerlink" title="CUDA编译器兼容C++17"></a>CUDA编译器兼容C++17</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.cu	这是一个.cu文件</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>CUDA 的语法，基本完全兼容 C++。包括 C++17 新特性，都可以用。甚至可以把任何一个 C++ 项目的文件后缀名全部改成 .cu，都能编译出来。</p>
<p>这是 CUDA 的一大好处，CUDA 和 C++ 的关系就像 C++ 和 C 的关系一样，大部分都兼容，因此能很方便地重用 C++ 现有的任何代码库，引用 C++ 头文件等。</p>
<p>host 代码和 device 代码写在同一个文件内，这是 OpenCL 做不到的。</p>
<h3 id="编写一段在GPU上运行的代码"><a href="#编写一段在GPU上运行的代码" class="headerlink" title="编写一段在GPU上运行的代码"></a>编写一段在GPU上运行的代码</h3><p>定义核函数 kernel，前面加上 <code>__global__</code> 修饰符，即可让它在 GPU 上执行。</p>
<ul>
<li><strong>核函数是我们后面主要接触的一段代码，就是设备上执行的程序段</strong></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//运行一下试试呢</span></span><br></pre></td></tr></table></figure>

<p>不过调用 kernel 时，不能直接 kernel()，而是要用 <code>kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;()</code> 这样的三重尖括号语法。为什么？这里面的两个 1 有什么用？稍后会说明。</p>
<p>运行以后，就会在 GPU 上执行 printf 了。（较旧的CUDA版本不支持直接打印）</p>
<p>这里的 kernel 函数在 GPU 上执行，称为核函数，用 <code>__global__</code> 修饰的就是核函数。</p>
<h3 id="运行没反应？同步一下！"><a href="#运行没反应？同步一下！" class="headerlink" title="运行没反应？同步一下！"></a>运行没反应？同步一下！</h3><p>如果直接编译运行刚刚那段代码，是不会打印出 Hello, world! 的。</p>
<p>这是因为 GPU 和 CPU 之间的通信，为了高效，是<strong>异步</strong>的。也就是 CPU 调用 <code>kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;()</code> 后，并不会立即在 GPU 上执行完毕，再返回。实际上只是把 kernel 这个任务推送到 GPU 的执行队列上，然后立即返回，并不会等待执行完毕。</p>
<p>因此可以调用 <code>cudaDeviceSynchronize()</code>，让 CPU 陷入等待，等 GPU 完成队列的所有任务后再返回。从而能够在 main 退出前等到 kernel 在 GPU 上执行完。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：</span></span><br><span class="line"><span class="comment">//Hello, world!</span></span><br></pre></td></tr></table></figure>

<h3 id="定义在GPU上的设备函数"><a href="#定义在GPU上的设备函数" class="headerlink" title="定义在GPU上的设备函数"></a>定义在GPU上的设备函数</h3><p><code>__global__</code> 用于定义核函数，它在 <strong>GPU 上执行</strong>，从 CPU 端通过三重尖括号语法调用，可以有参数，不可以有返回值。</p>
<p>而 <code>__device__</code> 则用于定义设备函数，它<strong>在 GPU 上执行</strong>，但是<strong>从 GPU 上调用</strong>的，而且<strong>不需要三重尖括号</strong>，和普通函数用起来一样，可以有参数，有返回值。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">say_hello</span><span class="params">()</span> </span>&#123;	<span class="comment">//内联修饰符</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">say_hello</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：</span></span><br><span class="line"><span class="comment">//Hello, world!</span></span><br></pre></td></tr></table></figure>

<p>即：host 可以调用 global；global 可以调用 device；device 可以调用 device。</p>
<h3 id="声明为内联函数"><a href="#声明为内联函数" class="headerlink" title="声明为内联函数"></a>声明为内联函数</h3><p>CUDA提供<code>__inline</code>关键字提示内联</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__device__ __inline__ <span class="type">void</span> <span class="title">say_hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">say_hello</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意，<strong>没有下划线的<code>inline</code></strong> 在现代 C++ 中的效果是声明一个函数为 weak 符号，和性能优化意义上的内联无关。</p>
<ul>
<li><p><code>inline</code> 在现代 C++ 中的主要作用是<strong>允许函数在多个编译单元中定义而不产生链接错误</strong>，而不再主要用于提示编译器进行函数的内联优化</p>
</li>
<li><p><code>inline</code> 函数在编译过程中，编译器会将该函数的符号标记为“弱符号”（weak symbol）。这意味着，如果同一个 <code>inline</code> 函数在多个编译单元中被定义，链接器会将这些定义视为等价的，并只保留一个定义，而不是报重复定义错误。这在多文件编译中避免了链接错误。</p>
</li>
<li><p>在现代 C++ 中，编译器的优化技术已经足够智能，能够自动决定是否将某个函数内联。</p>
</li>
</ul>
<p>优化意义上的内联指把函数体直接放到调用者那里去。</p>
<p>因此 CUDA 编译器提供了一个“私货”关键字：<code>__inline__</code> 来声明一个函数为内联。不论是 CPU 函数还是 GPU 函数都可以使用，只要你用的 CUDA 编译器。GCC 编译器相应的私货则是 <code>__attribute__((“inline”))</code>。</p>
<p>注意，声明为 <code>__inline__</code> <strong>不一定</strong>就保证内联了，如果函数太大编译器可能会放弃内联化。因此 CUDA 还提供 <code>__forceinline__</code> 这个关键字来强制一个函数为内联。GCC 也有相应的 <code>__attribute__((“always_inline”))</code>。</p>
<p>此外，还有 <code>__noinline__</code> 来禁止内联优化。</p>
<h3 id="定义在-cpu-上的主机函数"><a href="#定义在-cpu-上的主机函数" class="headerlink" title="定义在 cpu 上的主机函数"></a>定义在 cpu 上的主机函数</h3><p><code>__device__</code> 将函数定义在 GPU 上，而 <code>__host__</code> 则相反，将函数定义在 CPU 上。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">say_hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world from GPU!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__host__ <span class="type">void</span> <span class="title">say_hello_host</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world from CPU!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">say_hello</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">say_hello_host</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：</span></span><br><span class="line"><span class="comment">//Hello, world from GPU!</span></span><br><span class="line"><span class="comment">//Hello, world from CPU!</span></span><br></pre></td></tr></table></figure>

<p>CUDA 完全兼容 C++，因此任何函数如果没有指明修饰符，则默认就是 <code>__host__</code>，即 CPU 上的函数。</p>
<h3 id="同时定义在-CPU-和-GPU-上"><a href="#同时定义在-CPU-和-GPU-上" class="headerlink" title="同时定义在 CPU 和 GPU 上"></a>同时定义在 CPU 和 GPU 上</h3><p>这两个修饰符并不冲突，通过 <code>__host__ __device__</code> 这样的双重修饰符，可以把函数同时定义在 CPU 和 GPU 上，这样 CPU 和 GPU 都可以调用。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">say_hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world from GPU!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">say_hello_host</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world from CPU!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">say_hello</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">say_hello_host</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出：</span></span><br><span class="line"><span class="comment">//Hello, world from GPU!</span></span><br><span class="line"><span class="comment">//Hello, world from CPU!</span></span><br></pre></td></tr></table></figure>

<p>此时，编译后会生成两个版本，CPU 会直接调用<code>__host__</code>版本， GPU 调用<code>__device__</code>版本</p>
<h3 id="给constexpr加点料"><a href="#给constexpr加点料" class="headerlink" title="给constexpr加点料"></a>给<code>constexpr</code>加点料</h3><p>CUDA提供了一个实验性选项<code>--expt-relaxed-constexpr</code></p>
<p>在CMake中配置使用：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_STANDARD <span class="number">17</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_BUILD_TYPE Release)</span><br><span class="line"></span><br><span class="line"><span class="keyword">project</span>(hellocuda LANGUAGES CXX CUDA)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(main main.cu)</span><br><span class="line"><span class="keyword">target_compile_options</span>(main PUBLIC $&lt;$&lt;COMPILE_LANGUAGE:CUDA&gt;:--expt-relaxed-constexpr&gt;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><p>这里使用了一个生成表达式语法，只对当前编译的语言是CUDA是起效</p>
</li>
<li><p>constexpr 函数在<strong>编译期</strong>执行</p>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// constexpr 函数在编译期执行</span></span><br><span class="line"><span class="comment">// 这个函数没有使用 __host__ 和 __device__ 修饰符，但是被两端成功调用</span></span><br><span class="line"><span class="function"><span class="keyword">constexpr</span> <span class="type">const</span> <span class="type">char</span> *<span class="title">cuthead</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> p + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="built_in">cuthead</span>(<span class="string">&quot;Gello, world!\n&quot;</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="built_in">cuthead</span>(<span class="string">&quot;Cello, world!\n&quot;</span>));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出：</span></span><br><span class="line"><span class="comment">// ello, world!</span></span><br><span class="line"><span class="comment">// ello, world!</span></span><br></pre></td></tr></table></figure>

<p>上面的<code>cuthead()</code>函数没有使用 <code>__host__</code> 和 <code>__device__</code> 修饰符，但是被两端成功调用。</p>
<p>这样相当于把 constexpr 函数自动变成 <code>__host__ __device__</code>修饰，从而两端都可以调用。</p>
<p>因为 constexpr 通常都是一些可以内联的函数，数学计算表达式之类的，一个个加上修饰太累了，所以产生了这个需求。</p>
<p>不过必须指定 <code>--expt-relaxed-constexpr</code> 这个选项才能用这个特性，我们可以用 CMake 的生成器表达式来实现只对 .cu 文件开启此选项（不然给到 gcc 就出错了）。</p>
<p>当然，constexpr 里没办法调用 printf，也不能用 <code>__syncthreads</code> 之类的 GPU 特有的函数，因此也不能完全替代 <code>__host__</code> 和 <code>__device__</code>。</p>
<h3 id="多段编译"><a href="#多段编译" class="headerlink" title="多段编译"></a>多段编译</h3><p>通过<code>#ifdef</code>指令针对CPU和GPU生成不同的代码</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__host__ __device__ <span class="type">void</span> <span class="title">say_hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __CUDA_ARCH__</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world from GPU!\n&quot;</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world from CPU!\n&quot;</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">say_hello</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">say_hello</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>CUDA 编译器具有多段编译的特点。</p>
<p>一段代码，会<strong>先送到 CPU 上的编译器</strong>（通常是系统自带的编译器比如 gcc 和 msvc）生成 CPU 部分的指令码。然后<strong>再送到 GPU 编译器</strong>生成 GPU 指令码。最后再链接成同一个文件，看起来好像只编译了一次一样，实际上你的代码会被预处理很多次。</p>
<p>在 GPU 编译模式下会定义 <code>__CUDA_ARCH__</code> 这个宏，利用 <code>#ifdef</code> 判断该宏是否定义，就可以判断当前是否处于 GPU 模式，从而实现一个函数针对 GPU 和 CPU 生成两份源码级不同的代码。</p>
<p><strong><code>__CUDA_ARCH__</code>是个版本号</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__host__ __device__ <span class="type">void</span> <span class="title">say_hello</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __CUDA_ARCH__</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world from GPU architecture %d!\n&quot;</span>, __CUDA_ARCH__);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world from CPU!\n&quot;</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">say_hello</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">say_hello</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出：</span></span><br><span class="line"><span class="comment">// Hello, world from GPU architecture 520 !</span></span><br><span class="line"><span class="comment">// Hello, world from CPU !</span></span><br></pre></td></tr></table></figure>

<p>其实 <code>__CUDA_ARCH__</code> 是一个整数，表示当前编译所针对的 GPU 的架构版本号是多少。这里是 520 表示版本号是 5.2.0，最后一位始终是 0 不用管，我们通常简称它的版本号为 52 就行了。</p>
<p>这个版本号是编译时指定的版本，不是运行时检测到的版本。编译器默认就是最老的 52，能兼容所有 GTX900 以上显卡。</p>
<h3 id="通过CMake设置架构版本号"><a href="#通过CMake设置架构版本号" class="headerlink" title="通过CMake设置架构版本号"></a>通过CMake设置架构版本号</h3><p>可以用 CMAKE_CUDA_ARCHITECTURES 这个变量，设置要针对哪个架构生成 GPU 指令码。</p>
<p>我的的显卡是 RTX4050，它的版本号是 89，因此最适合它用的指令码版本是 89。</p>
<p>如果不指定，编译器默认的版本号是 52，它是针对 GTX900 系列显卡的。</p>
<p>不过英伟达的架构版本都是向前兼容的，即版本号为 89 的 RTX4050 也可以运行版本号为 52 的指令码，虽然不够优化，但是至少能用。也就是要求：<strong>编译期指定的版本 ≤ 运行时显卡的版本</strong>。</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.18</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定CUDA标准版本</span></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CUDA_STANDARD <span class="number">17</span>)</span><br><span class="line"><span class="comment"># 设置CUDA架构版本</span></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CUDA_ARCHITECTURES <span class="number">86</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">project</span>(cuda_test LANGUAGES CXX CUDA)</span><br></pre></td></tr></table></figure>

<ul>
<li>可以在Nvidia官网查看自己的GPU架构，我的RTX4050是8.9</li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-gpus#collapseOne">官网链接</a></li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/Clip_2024-10-26_00-44-54.png" alt="Clip_2024-10-26_00-44-54"></p>
<p><strong>坑点！版本号不能太新了</strong></p>
<p><em>由于我的显卡是目前最新架构，无法复现这个错误，请自行测试</em></p>
<p>假设你的显卡是RTX3000系列，这里设置了 RTX4000 系列的架构版本号 89，在 RTX3000系上就运行不出结果。</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.18</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定CUDA标准版本</span></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CUDA_STANDARD <span class="number">17</span>)</span><br><span class="line"><span class="comment"># 设置CUDA架构版本</span></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CUDA_ARCHITECTURES <span class="number">89</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">project</span>(cuda_test LANGUAGES CXX CUDA)</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__host__ __device__ <span class="type">void</span> <span class="title">say_hello</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __CUDA_ARCH__</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world from GPU architecture %d!\n&quot;</span>, __CUDA_ARCH__);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world from CPU!\n&quot;</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">say_hello</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">say_hello</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出：</span></span><br><span class="line"><span class="comment">// Hello, world from CPU !</span></span><br></pre></td></tr></table></figure>

<p>最坑的是不会报错！也不输出任何东西！就像没有那个 kernel 函数一样！所以一定要注意调对版本号，否则<strong>只有 CPU 上的代码被执行了</strong>。</p>
<h4 id="指定多个版本号"><a href="#指定多个版本号" class="headerlink" title="指定多个版本号"></a>指定多个版本号</h4><p>可以指定多个版本号，之间用分号分割。</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span>(CMAKE_CUDA_ARCHITECTURES <span class="number">52</span>;<span class="number">70</span>;<span class="number">75</span>;<span class="number">86</span>;<span class="number">89</span>)</span><br></pre></td></tr></table></figure>

<p>运行时可以自动选择最适合当前显卡的版本号，通常用于打包发布的时候。</p>
<p>不过这样会导致 GPU 编译器重复编译很多遍，每次针对不同的架构，所以编译会变得非常慢，生成的可执行文件也会变大。</p>
<p>通常在自己的电脑上用时，只要根据自己显卡的指定一个版本号即可。</p>
<p>如果 CMakeLists.txt 里没有指定，也可以从命令行参数指定：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmake -B build -DCMAKE_CUDA_ARCHITECTURES=&quot;52;70;75;86;89&quot;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我的运行输出：</span></span><br><span class="line">ming@MING:~/project/cuda/cuda_test$ ./build/mytest </span><br><span class="line">Hello, world from GPU architecture 890!</span><br><span class="line">Hello, world from CPU!</span><br></pre></td></tr></table></figure>

<h2 id="第一章：线程与板块"><a href="#第一章：线程与板块" class="headerlink" title="第一章：线程与板块"></a>第一章：线程与板块</h2><h3 id="三重尖括号里的数字"><a href="#三重尖括号里的数字" class="headerlink" title="三重尖括号里的数字"></a>三重尖括号里的数字</h3><p>刚刚说了 CUDA 的核函数调用时需要用 kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;() 这种奇怪的语法，这里面的数字代表什么意思呢？</p>
<p>不妨把 &lt;&lt;&lt;1, 1&gt;&gt;&gt; 改成 &lt;&lt;&lt;1, 3&gt;&gt;&gt; 试试看。你会看到 Hello, world! 打印了三遍！</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello, world\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">3</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Hello, world! </span></span><br><span class="line"><span class="comment">// Hello, world! </span></span><br><span class="line"><span class="comment">// Hello, world! </span></span><br></pre></td></tr></table></figure>

<p>原来，三重尖括号里的第二个参数决定着启动 kernel 时所用 GPU 的<strong>线程</strong>数量。</p>
<p>GPU 是为并行而生的，可以开启很大数量的线程，用于处理大吞吐量的数据。</p>
<h3 id="获取线程编号"><a href="#获取线程编号" class="headerlink" title="获取线程编号"></a>获取线程编号</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123; <span class="built_in">printf</span>(<span class="string">&quot;Thread %d\n&quot;</span>, threadIdx.x); &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">3</span>&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Thread 0</span></span><br><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line"><span class="comment">// Thread 2</span></span><br></pre></td></tr></table></figure>

<p>可以通过 <code>threadIdx.x</code> 获取当前线程的编号，我们打印一下试试看。</p>
<p>这是 CUDA 中的特殊变量之一，只有在<strong>核函数</strong>里才可以访问。</p>
<p>可以看到线程编号从0开始计数，打印出了0，1，2。这也是我们指定了线程数量为 3 的缘故。</p>
<ul>
<li>等等，为什么后面有个 .x？稍后再说明。</li>
</ul>
<h3 id="获取线程数量"><a href="#获取线程数量" class="headerlink" title="获取线程数量"></a>获取线程数量</h3><p>还可以用 blockDim.x 获取当前线程数量，也就是我们在尖括号里指定的 3。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Thread %d of %d\n&quot;</span>, threadIdx.x, blockDim.x);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">3</span>&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Thread 0 of 3</span></span><br><span class="line"><span class="comment">// Thread 1 of 3</span></span><br><span class="line"><span class="comment">// Thread 2 of 3</span></span><br></pre></td></tr></table></figure>

<h3 id="线程之上：板块"><a href="#线程之上：板块" class="headerlink" title="线程之上：板块"></a>线程之上：板块</h3><p>接下来我们修改<code>&quot;&lt;&lt;&lt; &gt;&gt;&gt;&quot;</code>中的另一个参数</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Thread %d of %d\n&quot;</span>, threadIdx.x, blockDim.x);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">2</span>, <span class="number">3</span>&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Thread 0 of 3</span></span><br><span class="line"><span class="comment">// Thread 1 of 3</span></span><br><span class="line"><span class="comment">// Thread 2 of 3</span></span><br><span class="line"><span class="comment">// Thread 0 of 3</span></span><br><span class="line"><span class="comment">// Thread 1 of 3</span></span><br><span class="line"><span class="comment">// Thread 2 of 3</span></span><br></pre></td></tr></table></figure>

<p>我们发现启动了六个线程，而且被分为两组。</p>
<p>CUDA 中还有一个比线程更大的概念，那就是<strong>板块（block）</strong>，一个板块可以有多个线程组成。这就是为什么刚刚获取线程数量的变量用的是 blockDim，实际上 blockDim 的含义是每个板块有多少个线程。</p>
<p>要指定板块的数量，只需调节三重尖括号里第一个参数即可。我们这里调成 2。总之：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;&lt;&lt;板块数量，每个板块中的线程数量&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>

<p>可以看到这里我们启动了两个板块，各有3个线程，都打印了一样的数据。</p>
<h3 id="获取板块编号和数量"><a href="#获取板块编号和数量" class="headerlink" title="获取板块编号和数量"></a>获取板块编号和数量</h3><ul>
<li><p>板块的编号可以用 blockIdx.x 获取。</p>
</li>
<li><p>板块的总数可以用 gridDim.x 获取。</p>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Block %d of %d, Thread %d of %d\n&quot;</span>, blockIdx.x, gridDim.x,</span><br><span class="line">         threadIdx.x, blockDim.x);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">2</span>, <span class="number">3</span>&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Block 1 of 2, Thread 0 of 3</span></span><br><span class="line"><span class="comment">// Block 1 of 2, Thread 1 of 3</span></span><br><span class="line"><span class="comment">// Block 1 of 2, Thread 2 of 3</span></span><br><span class="line"><span class="comment">// Block 0 of 2, Thread 0 of 3</span></span><br><span class="line"><span class="comment">// Block 0 of 2, Thread 1 of 3</span></span><br><span class="line"><span class="comment">// Block 0 of 2, Thread 2 of 3</span></span><br></pre></td></tr></table></figure>

<p>可以看到这里执行了两个板块，每个板块又有三个线程，总共有2*3&#x3D;6个线程。</p>
<p>而且看到这里板块1在板块0之前执行了(你的可能不是)，这是因为板块之间是高度并行的，不保证执行的先后顺序。线程之间也是，这里线程打印顺序没乱，不过是碰巧小于32而已。</p>
<ul>
<li>关于这个32我们后边会讨论</li>
</ul>
<h3 id="理解线程管理"><a href="#理解线程管理" class="headerlink" title="理解线程管理"></a>理解线程管理</h3><p>接下来我们整体理解一下CUDA中的线程管理，CUDA将计算任务划分为多个层次，包括线程、板块（block）和网格（grid）。</p>
<h4 id="线程、板块与网格的层次结构"><a href="#线程、板块与网格的层次结构" class="headerlink" title="线程、板块与网格的层次结构"></a>线程、板块与网格的层次结构</h4><ol>
<li>**线程 (Thread)**：是CUDA中的基本执行单元。每个线程可以独立地执行相同的代码，但处理不同的数据。</li>
<li>**板块 (Block)**：是由多个线程组成的集合。一个板块内部的线程可以共享内存并进行协作，使得数据传输和计算更加高效。</li>
<li>**网格 (Grid)**：是包含若干个板块的集合，代表整个计算任务。一个网格可以是多维的（如一维、二维或三维），以适应不同类型的数据结构。</li>
</ol>
<h4 id="从属关系"><a href="#从属关系" class="headerlink" title="从属关系"></a>从属关系</h4><p>在CUDA的层次结构中，线程、板块和网格之间存在如下从属关系：</p>
<ul>
<li><strong>线程 &lt; 板块 &lt; 网格</strong></li>
</ul>
<p>这种关系说明，一个网格由多个板块组成，而每个板块又由多个线程组成。</p>
<h4 id="重要变量"><a href="#重要变量" class="headerlink" title="重要变量"></a>重要变量</h4><p>在CUDA中，有几个重要的变量用于访问当前线程和板块的信息：</p>
<table>
<thead>
<tr>
<th>变量名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong><code>threadIdx</code></strong></td>
<td>当前线程在其所属板块中的编号。</td>
</tr>
<tr>
<td><strong><code>blockDim</code></strong></td>
<td>当前板块中线程的数量。</td>
</tr>
<tr>
<td><strong><code>blockIdx</code></strong></td>
<td>当前板块在网格中的编号。</td>
</tr>
<tr>
<td><strong><code>gridDim</code></strong></td>
<td>网格中总的板块数量。</td>
</tr>
</tbody></table>
<h4 id="调用语法"><a href="#调用语法" class="headerlink" title="调用语法"></a>调用语法</h4><p>在CUDA中，调用内核函数的语法为：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel_function&lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt;(parameters);</span><br></pre></td></tr></table></figure>

<p>这里，<code>gridDim</code>指定了网格的维度和大小，而<code>blockDim</code>则定义了每个板块的线程数量。通过合理设置这两个参数，可以充分利用GPU的并行计算能力。</p>
<p>我们在CPU编程中的经验告诉我们，只要有了线程，就可以实现并行，为什么还要引入板块、网格这些概念？稍后我们就会进行说明。</p>
<h4 id="“扁平化”理解"><a href="#“扁平化”理解" class="headerlink" title="“扁平化”理解"></a>“扁平化”理解</h4><p>通过上面的这些变量，我们可以获取总线程数、总板块数以及当前线程的全局编号等等，方便管理和访问数据。下面是几个常用的公式：</p>
<p><strong>总板块数</strong>：</p>
<p>gridDim 就表示着板块的数量，一维情况下就是 gridDim.x</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> totalBlocks = gridDim.x;	<span class="comment">// 只考虑x维度</span></span><br></pre></td></tr></table></figure>

<p><strong>总线程数</strong>：</p>
<p><strong>网格中块的数量</strong>乘以<strong>每个块中的线程数量</strong>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> totalThreads = gridDim.x * blockDim.x;	<span class="comment">// 只考虑x维度</span></span><br></pre></td></tr></table></figure>

<p><code>gridDim.x</code>是网格在x维度上块的数量，而<code>blockDim.x</code>是每个块中线程的数量</p>
<p><strong>当前线程的全局编号</strong>：</p>
<p>全局编号可以唯一标识每个线程在整个网格中的位置，就可以控制每个线程操作不同的数据。</p>
<p>因为索引下标是从0开始，所以我们可以这样计算：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> globalThreadId = blockIdx.x * blockDim.x + threadIdx.x;	<span class="comment">// 只考虑x维度</span></span><br></pre></td></tr></table></figure>

<p><code>blockIdx.x</code>：当前块在网格中的索引（0,1,2……）</p>
<p><code>blockDim.x</code>：块中线程的数量（注意这里不从0开始）</p>
<p><code>threadIdx.x</code>：当前线程在其所属块中的索引(0,1,2……)</p>
<p><strong>下面是示例：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 当前线程的全局编号</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">int</span> globalThreadId = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取总板块数</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">int</span> totalBlocks = gridDim.x;  <span class="comment">// 网格中块的数量</span></span><br><span class="line">  <span class="comment">// 获取总线程数</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">int</span> totalThreads = gridDim.x * blockDim.x;  <span class="comment">// 网格中的总线程数</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 打印输出（调试信息）</span></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Global Thread ID: %u, Total Blocks: %u, Total Threads: %u\n&quot;</span>,</span><br><span class="line">         globalThreadId, totalBlocks, totalThreads);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">2</span>, <span class="number">3</span>&gt;&gt;&gt;();       <span class="comment">// 启动2个块，每个块3个线程</span></span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();  <span class="comment">// 等待所有线程完成</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Global Thread ID: 0, Total Blocks: 2, Total Threads: 6</span></span><br><span class="line"><span class="comment">// Global Thread ID: 1, Total Blocks: 2, Total Threads: 6</span></span><br><span class="line"><span class="comment">// Global Thread ID: 2, Total Blocks: 2, Total Threads: 6</span></span><br><span class="line"><span class="comment">// Global Thread ID: 3, Total Blocks: 2, Total Threads: 6</span></span><br><span class="line"><span class="comment">// Global Thread ID: 4, Total Blocks: 2, Total Threads: 6</span></span><br><span class="line"><span class="comment">// Global Thread ID: 5, Total Blocks: 2, Total Threads: 6</span></span><br></pre></td></tr></table></figure>

<ul>
<li>剧透一下：实际上 GPU 的板块相当于 CPU 的线程，GPU 的线程相当于 CPU 的<strong>SIMD</strong>，可以这样理解，但不完全等同。</li>
<li>SIMD（Single Instruction, Multiple Data）是一种计算机架构设计理念，允许在单个指令下对多个数据元素进行并行处理。更多内容请自行了解</li>
</ul>
<h4 id="图形理解"><a href="#图形理解" class="headerlink" title="图形理解"></a>图形理解</h4><p>线程组织结构图：</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/Clip_2024-11-04_01-55-59.png" class="" title="Clip_2024-11-04_01-55-59">

<p>线程计算：</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/image-20241104015521193.png" class="" title="image-20241104015521193">

<h3 id="三维的板块和线程编号"><a href="#三维的板块和线程编号" class="headerlink" title="三维的板块和线程编号"></a>三维的板块和线程编号</h3><p>CUDA 也支持三维的板块和线程区间。</p>
<p>只要在三重尖括号内指定的参数改成 dim3 类型即可。dim3 的构造函数就是接受三个无符号整数（unsigned int）非常简单。</p>
<p>dim3(x, y, z)</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Block (%d,%d,%d) of (%d,%d,%d), Thread (%d,%d,%d) of (%d,%d,%d)\n&quot;</span>,</span><br><span class="line">         blockIdx.x, blockIdx.y, blockIdx.z, gridDim.x, gridDim.y, gridDim.z,</span><br><span class="line">         threadIdx.x, threadIdx.y, threadIdx.z, blockDim.x, blockDim.y,</span><br><span class="line">         blockDim.z);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="built_in">dim3</span>(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="built_in">dim3</span>(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Block (0,0,0) of (2,1,1), Thread (0,0,0) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (0,0,0) of (2,1,1), Thread (1,0,0) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (0,0,0) of (2,1,1), Thread (0,1,0) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (0,0,0) of (2,1,1), Thread (1,1,0) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (0,0,0) of (2,1,1), Thread (0,0,1) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (0,0,0) of (2,1,1), Thread (1,0,1) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (0,0,0) of (2,1,1), Thread (0,1,1) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (0,0,0) of (2,1,1), Thread (1,1,1) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (1,0,0) of (2,1,1), Thread (0,0,0) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (1,0,0) of (2,1,1), Thread (1,0,0) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (1,0,0) of (2,1,1), Thread (0,1,0) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (1,0,0) of (2,1,1), Thread (1,1,0) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (1,0,0) of (2,1,1), Thread (0,0,1) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (1,0,0) of (2,1,1), Thread (1,0,1) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (1,0,0) of (2,1,1), Thread (0,1,1) of (2,2,2)</span></span><br><span class="line"><span class="comment">// Block (1,0,0) of (2,1,1), Thread (1,1,1) of (2,2,2)</span></span><br></pre></td></tr></table></figure>

<p>这样在核函数里就可以通过 threadIdx.y 获取 y 方向的线程编号，以此类推。</p>
<h4 id="二维："><a href="#二维：" class="headerlink" title="二维："></a>二维：</h4><p>只需要把 dim3 最后一位（z方向）的值设为 1 即可。这样就只有 xy 方向有大小，就相当于二维了，不会有性能损失。</p>
<ul>
<li>实际上一维的 <code>&lt;&lt;&lt;m, n&gt;&gt;&gt;</code> 不过是 <code>&lt;&lt;&lt;dim3(m, 1, 1), dim3(n, 1, 1)&gt;&gt;&gt;</code> 的简写而已。</li>
</ul>
<h4 id="为什么要分三维这种结构？"><a href="#为什么要分三维这种结构？" class="headerlink" title="为什么要分三维这种结构？"></a>为什么要分三维这种结构？</h4><p>之所以会把 blockDim 和 gridDim 分三维主要是因为 GPU 的业务常常涉及到三维图形学和二维图像，觉得这样很方便，并不一定 GPU 硬件上是三维这样排列的。</p>
<p>三维情况下同样可以获取总的线程编号（扁平化），只需要分别对三个维度进行操作</p>
<ul>
<li><p>如需总的线程数量：blockDim * gridDim</p>
</li>
<li><p>如需总的线程编号：blockDim * blockIdx + threadIdx</p>
</li>
</ul>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/image-20241104020157023.png" class="" title="image-20241104020157023">

<h3 id="补充：分离-device-函数的声明和定义"><a href="#补充：分离-device-函数的声明和定义" class="headerlink" title="补充：分离 device 函数的声明和定义"></a>补充：分离 <strong>device</strong> 函数的声明和定义</h3><h4 id="出错："><a href="#出错：" class="headerlink" title="出错："></a>出错：</h4><p>我们在hello.cu中定义一个设备上的函数</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// hello.cu</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">say_hello</span><span class="params">()</span> </span>&#123;  <span class="comment">// 定义</span></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Hello, world!\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在main.cu文件中声明并调用：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.cu</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">say_hello</span><span class="params">()</span></span>;  <span class="comment">// 声明</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123; <span class="built_in">say_hello</span>(); &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>进行编译就会报错：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ptxas fatal   : Unresolved extern function &#x27;_Z9say_hellov&#x27;</span><br></pre></td></tr></table></figure>

<p>默认情况下 GPU 函数必须定义在同一个文件里。如果你试图分离声明和定义，调用另一个文件里的 <code>__device__</code> 或 <code>__global__</code> 函数，就会出错。</p>
<h4 id="解决："><a href="#解决：" class="headerlink" title="解决："></a>解决：</h4><p>开启 <code>CMAKE_CUDA_SEPARABLE_COMPILATION</code> 选项（设为 ON），即可启用分离声明和定义的支持。</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_STANDARD <span class="number">17</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_BUILD_TYPE Release)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_CUDA_SEPARABLE_COMPILATION <span class="keyword">ON</span>)    <span class="comment"># 分离编译</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">project</span>(hellocuda LANGUAGES CXX CUDA)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(main main.cu hello.cu)</span><br></pre></td></tr></table></figure>

<p>但是，我们仍然建议把要相互调用的 <code>__device__</code> 函数放在同一个文件，这样方便编译器自动内联优化（第四课讲过）</p>
<h4 id="两种开启方式：全局有效or仅针对单个程序"><a href="#两种开启方式：全局有效or仅针对单个程序" class="headerlink" title="两种开启方式：全局有效or仅针对单个程序"></a>两种开启方式：全局有效or仅针对单个程序</h4><ul>
<li>对下方所有的程序启用（推荐）：</li>
</ul>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span>(CMAKE_CUDA_SEPARABLE_COMPILATION <span class="keyword">ON</span>)    <span class="comment"># 分离编译</span></span><br></pre></td></tr></table></figure>

<ul>
<li>只对 main 这个程序启用：</li>
</ul>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_executable</span>(main main.cu hello.cu)</span><br><span class="line"><span class="keyword">set_property</span>(<span class="keyword">TARGET</span> main PROPERTY CUDA_SEPARABLE_COMPILATION <span class="keyword">ON</span>)	<span class="comment"># 为main设置属性</span></span><br></pre></td></tr></table></figure>

<ul>
<li>顺便一提，CXX_STANDARD 和 CUDA_ARCHITECTURES 也有这两种方式，一般推荐直接设置全局的 CMAKE_CXX_STANDARD 即可应用到全部 add_executable&#x2F;add_library 的对象上，比较方便。</li>
</ul>
<h4 id="进一步：核函数调用核函数"><a href="#进一步：核函数调用核函数" class="headerlink" title="进一步：核函数调用核函数"></a><strong>进一步：核函数调用核函数</strong></h4><p>从 Kelper 架构开始，<code>__global__</code> 里可以调用另一个 <code>__global__</code>，也就是说核函数可以调用另一个核函数，且其三重尖括号里的板块数和线程数可以动态指定，无需先传回到 CPU 再进行调用，这是 CUDA 特有的能力。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">another</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;another: Thread %d of %d\n&quot;</span>, threadIdx.x, blockDim.x);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;kernel: Thread %d of %d\n&quot;</span>, threadIdx.x, blockDim.x);</span><br><span class="line">  <span class="type">int</span> numthreads = threadIdx.x * threadIdx.x + <span class="number">1</span>;</span><br><span class="line">  another&lt;&lt;&lt;<span class="number">1</span>, numthreads&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;kernel: called another with %d threads\n&quot;</span>, numthreads);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">3</span>&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// /kernel: Thread 0 of 3</span></span><br><span class="line"><span class="comment">// kernel: Thread 1 of 3</span></span><br><span class="line"><span class="comment">// kernel: Thread 2 of 3</span></span><br><span class="line"><span class="comment">// kernel: called another with 1 threads</span></span><br><span class="line"><span class="comment">// kernel: called another with 2 threads</span></span><br><span class="line"><span class="comment">// kernel: called another with 5 threads</span></span><br><span class="line"><span class="comment">// another: Thread 0 of 1</span></span><br><span class="line"><span class="comment">// another: Thread 0 of 2</span></span><br><span class="line"><span class="comment">// another: Thread 1 of 2</span></span><br><span class="line"><span class="comment">// another: Thread 0 of 5</span></span><br><span class="line"><span class="comment">// another: Thread 1 of 5</span></span><br><span class="line"><span class="comment">// another: Thread 2 of 5</span></span><br><span class="line"><span class="comment">// another: Thread 3 of 5</span></span><br><span class="line"><span class="comment">// another: Thread 4 of 5</span></span><br></pre></td></tr></table></figure>

<p>常用于这种情况：需要从 GPU 端动态计算出 blockDim 和 gridDim，而又不希望导回数据到 CPU 导致强制同步影响性能。</p>
<ul>
<li>这种模式被称为<strong>动态并行</strong>（dynamic parallelism），OpenGL 有一个 glDispatchComputeIndirect 的 API 和这个很像，但毕竟没有 CUDA 可以直接在核函数里调用核函数并指定参数这么方便……</li>
</ul>
<p>不过，这个功能同样需要开启 CUDA_SEPARABLE_COMPILATION。</p>
<h2 id="第二章：内存管理"><a href="#第二章：内存管理" class="headerlink" title="第二章：内存管理"></a>第二章：内存管理</h2><h3 id="怎样从核函数返回数据？"><a href="#怎样从核函数返回数据？" class="headerlink" title="怎样从核函数返回数据？"></a>怎样从核函数返回数据？</h3><p>我们试着把 kernel 的返回类型声明为 int，试图从 GPU 返回数据到 CPU。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">int</span> <span class="title">kernel</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="number">42</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> ret = kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, ret);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/Clip_2024-11-04_23-55-59.png" class="" title="Clip_2024-11-04_23-55-59">

<p>但发现这样做会在编译期出错，为什么？</p>
<p>刚刚说了 kernel 的调用是<strong>异步</strong>的，返回的时候，并不会实际让 GPU 把核函数执行完毕，必须 cudaDeviceSynchronize() 等待它执行完毕（和线程的 join 很像）。</p>
<p>所以，不可能从 kernel 里通过返回值获取 GPU 数据，因为 kernel 返回时核函数并没有真正在 GPU 上执行。所以核函数返回类型必须是 void。</p>
<h3 id="试图解决：通过指针传递"><a href="#试图解决：通过指针传递" class="headerlink" title="试图解决：通过指针传递"></a>试图解决：通过指针传递</h3><p>那你可能会想，既然不能返回，那作为指针传入局部变量的引用，不就好了。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *pret)</span> </span>&#123; *pret = <span class="number">42</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> ret = <span class="number">0</span>;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(&amp;ret);</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, ret);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 0</span></span><br></pre></td></tr></table></figure>

<p>这样，在 cudaDeviceSynchronize() 以后，应该可以获取数据了吧？</p>
<p>结果令人失望，尽管给 kernel 传了指向 ret 的指针，但 ret 的值并没有被改写成功。</p>
<h3 id="分析返回错误的代码"><a href="#分析返回错误的代码" class="headerlink" title="分析返回错误的代码"></a>分析返回错误的代码</h3><p>CUDA 的函数，如 cudaDeviceSynchronize()。</p>
<p>它们出错时，并不会直接终止程序，也不会抛出 C++ 的异常，而是返回一个错误代码，告诉你出的具体什么错误，这是出于通用性考虑。</p>
<p>这个错误代码的类型是 cudaError_t，其实就是个 enum 类型，相当于 int。</p>
<p>可以通过 <code>cudaGetErrorName</code> 获取该 enum 的具体名字。这里显示错误号为 700，具体名字是 cudaErrorIllegalAddress。意思是我们访问了非法的地址，和 CPU 上的 Segmentation Fault 差不多。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *pret)</span> </span>&#123; *pret = <span class="number">42</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> ret = <span class="number">0</span>;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(&amp;ret);</span><br><span class="line">  cudaError_t err = <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;error code: %d\n&quot;</span>, err);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;error name: %s\n&quot;</span>, <span class="built_in">cudaGetErrorName</span>(err));</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, ret);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// error code: 700</span></span><br><span class="line"><span class="comment">// error name: cudaErrorIllegalAddress</span></span><br><span class="line"><span class="comment">// 0</span></span><br></pre></td></tr></table></figure>

<h3 id="helper-cuda-h工具"><a href="#helper-cuda-h工具" class="headerlink" title="helper_cuda.h工具"></a>helper_cuda.h工具</h3><p>其实 CUDA toolkit 安装时，会默认附带一系列案例代码，这些案例中提供了一些非常有用的头文件和工具类，比如这个文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/cuda/samples/common/inc/helper_cuda.h</span><br></pre></td></tr></table></figure>

<p>把它和 helper_string.h 一起拷到头文件目录里，然后改一下 CMakeLists.txt 让它包含这个头文件目录。</p>
<ul>
<li>如果你安装CUDA时没有选择samples包，直接在<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/cuda-samples">CUDA-Sample的GitHub仓库</a>寻找并下载即可。</li>
</ul>
<p>它定义了 checkCudaErrors 这个宏，使用时只需：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">checkCudaErrors(cudaDeviceSynchronize())</span><br></pre></td></tr></table></figure>

<p>即可自动帮你检查错误代码并打印在终端，然后退出。还会报告出错所在的行号，函数名等，很方便。</p>
<p><strong>示例：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *pret)</span> </span>&#123; *pret = <span class="number">42</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> ret = <span class="number">0</span>;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(&amp;ret);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// CUDA error at 02_memory/04/main.cu:12 code=700(cudaErrorIllegalAddress)</span></span><br><span class="line"><span class="comment">// &quot;cudaDeviceSynchronize()&quot;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_STANDARD <span class="number">17</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_BUILD_TYPE Release)</span><br><span class="line"></span><br><span class="line"><span class="keyword">project</span>(hellocuda LANGUAGES CXX CUDA)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(main main.cu)</span><br><span class="line"><span class="keyword">target_include_directories</span>(main PUBLIC ../../<span class="keyword">include</span>)   <span class="comment"># 注意添加头文件路径</span></span><br></pre></td></tr></table></figure>

<ul>
<li>注意修改为你的头文件路径</li>
</ul>
<h3 id="在堆上分配试试呢？"><a href="#在堆上分配试试呢？" class="headerlink" title="在堆上分配试试呢？"></a>在堆上分配试试呢？</h3><p>你可能会想，难道是因为我的 ret 创建在栈上，所以 GPU 不能访问，才出错的？</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *pret)</span> </span>&#123; *pret = <span class="number">42</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> *pret = (<span class="type">int</span> *)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(<span class="type">int</span>));	<span class="comment">// 申请堆上内存</span></span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(pret);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">free</span>(pret);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// CUDA error at /home/ming/project/cuda/08/02_memory/05/main.cu:12</span></span><br><span class="line"><span class="comment">// code=700(cudaErrorIllegalAddress) &quot;cudaDeviceSynchronize()&quot;</span></span><br></pre></td></tr></table></figure>

<p>试图用 malloc 在堆上分配一个 int 来给 GPU 访问，结果还是失败了。</p>
<h3 id="原因：GPU-使用独立的显存，不能访问-CPU-内存"><a href="#原因：GPU-使用独立的显存，不能访问-CPU-内存" class="headerlink" title="原因：GPU 使用独立的显存，不能访问 CPU 内存"></a>原因：GPU 使用独立的显存，不能访问 CPU 内存</h3><p>原来，GPU 和 CPU 各自使用着独立的内存。CPU 的内存称为主机内存(host)。GPU 使用的内存称为设备内存(device)，它是显卡上板载的，速度更快，又称显存。</p>
<p>而不论栈还是 malloc 分配的都是 CPU 上的内存，所以自然是无法被 GPU 访问到。</p>
<p>因此可以用用 cudaMalloc 分配 GPU 上的显存，这样就不出错了，结束时 cudaFree 释放。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *pret)</span> </span>&#123; *pret = <span class="number">42</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> *pret;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMalloc</span>(&amp;pret, <span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(pret);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">cudaFree</span>(pret);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意到 cudaMalloc 的返回值已经用来表示错误代码，所以返回指针只能通过 &amp;pret 二级指针。</p>
<h3 id="反之亦然，CPU-也不能访问-GPU-内存地址"><a href="#反之亦然，CPU-也不能访问-GPU-内存地址" class="headerlink" title="反之亦然，CPU 也不能访问 GPU 内存地址"></a>反之亦然，CPU 也不能访问 GPU 内存地址</h3><p>你可能已经迫不及待想通过 *pret 访问其返回值了。但是不行，因为 GPU 访问不了 CPU 的内存地址，同理，CPU 也访问不了 GPU 的内存地址。一访问 CPU 就奔溃了。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *pret)</span> </span>&#123; *pret = <span class="number">42</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> *pret;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMalloc</span>(&amp;pret, <span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(pret);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;result: %d\n&quot;</span>, *pret);</span><br><span class="line">  <span class="built_in">cudaFree</span>(pret);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 报错：Segmentation fault (core dumped)</span></span><br></pre></td></tr></table></figure>

<h3 id="跨-GPU-CPU-地址空间拷贝数据"><a href="#跨-GPU-CPU-地址空间拷贝数据" class="headerlink" title="跨 GPU&#x2F;CPU 地址空间拷贝数据"></a>跨 GPU&#x2F;CPU 地址空间拷贝数据</h3><p>因此可以用 cudaMemcpy，它能够在 GPU 和 CPU 内存之间拷贝数据。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *pret)</span> </span>&#123; *pret = <span class="number">42</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> *pret;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMalloc</span>(&amp;pret, <span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(pret);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> ret;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMemcpy</span>(&amp;ret, pret, <span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost));	<span class="comment">// 数据拷贝</span></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;result: %d\n&quot;</span>, ret);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(pret);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// result: 42</span></span><br></pre></td></tr></table></figure>

<p>这里我们希望把 GPU 上的内存数据拷贝到 CPU 内存上，也就是从设备内存(device)到主机内存(host)，因此第四个参数指定为 cudaMemcpyDeviceToHost。</p>
<p>同理，还有 cudaMemcpyHostToDevice 和 cudaMemcpyDeviceToDevice。</p>
<h3 id="cudaMemcpy-会自动同步！"><a href="#cudaMemcpy-会自动同步！" class="headerlink" title="cudaMemcpy 会自动同步！"></a>cudaMemcpy 会自动同步！</h3><p>注意：cudaMemcpy 会自动进行同步操作，即和 cudaDeviceSynchronize() 等价！因此前面的 cudaDeviceSynchronize() 实际上可以删掉了。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *pret)</span> </span>&#123; *pret = <span class="number">42</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> *pret;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMalloc</span>(&amp;pret, <span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(pret);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// cudaDeviceSynchronize();     // cudaMemcpy隐含同步</span></span><br><span class="line">  <span class="type">int</span> ret;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMemcpy</span>(&amp;ret, pret, <span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost));</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;result: %d\n&quot;</span>, ret);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(pret);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// result: 42</span></span><br></pre></td></tr></table></figure>

<h3 id="统一内存地址技术-（Unified-Memory）"><a href="#统一内存地址技术-（Unified-Memory）" class="headerlink" title="统一内存地址技术 （Unified Memory）"></a>统一内存地址技术 （Unified Memory）</h3><p>还有一种在比较新的显卡上支持的特性，那就是统一内存(managed)，只需把 cudaMalloc 换成 cudaMallocManaged 即可，释放时也是通过 cudaFree。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *pret)</span> </span>&#123; *pret = <span class="number">42</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> *pret;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;pret, <span class="built_in">sizeof</span>(<span class="type">int</span>)));  <span class="comment">// 统一内存分配</span></span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(pret);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;result: %d\n&quot;</span>, *pret);</span><br><span class="line">  <span class="built_in">cudaFree</span>(pret);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// result: 42</span></span><br></pre></td></tr></table></figure>

<p>这样分配出来的地址，不论在 CPU 还是 GPU 上都是一模一样的，都可以访问。而且拷贝也会自动按需进行（当从 CPU 访问时），无需手动调用 cudaMemcpy，大大方便了编程人员，特别是含有指针的一些数据结构。</p>
<h3 id="注意区分"><a href="#注意区分" class="headerlink" title="注意区分"></a>注意区分</h3><ul>
<li><p>主机内存(host)：malloc、free</p>
</li>
<li><p>设备内存(device)：cudaMalloc、cudaFree</p>
</li>
<li><p>统一内存(managed)：cudaMallocManaged、cudaFree</p>
</li>
</ul>
<p>如果我没记错的话，统一内存是从 Pascal 架构开始支持的，也就是 GTX9 开头及以上。</p>
<p>虽然方便，但并非完全没有开销，有条件的话还是尽量用分离的设备内存和主机内存吧。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/image-20241105002813939.png" class="" title="image-20241105002813939">

<h2 id="第三章：GPU上的数组"><a href="#第三章：GPU上的数组" class="headerlink" title="第三章：GPU上的数组"></a>第三章：GPU上的数组</h2><h3 id="分配一个数组"><a href="#分配一个数组" class="headerlink" title="分配一个数组"></a>分配一个数组</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    arr[i] = i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">32</span>;</span><br><span class="line">  <span class="type">int</span> *arr;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;arr, n * <span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(arr, n);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;arr[%d]: %d\n&quot;</span>, i, arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">cudaFree</span>(arr);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// arr[0]: 0</span></span><br><span class="line"><span class="comment">// arr[1]: 1</span></span><br><span class="line"><span class="comment">// arr[2]: 2</span></span><br><span class="line"><span class="comment">// arr[3]: 3</span></span><br><span class="line"><span class="comment">// arr[4]: 4</span></span><br><span class="line"><span class="comment">// arr[5]: 5</span></span><br><span class="line"><span class="comment">// arr[6]: 6</span></span><br><span class="line"><span class="comment">// arr[7]: 7</span></span><br><span class="line"><span class="comment">// arr[8]: 8</span></span><br><span class="line"><span class="comment">// arr[9]: 9</span></span><br><span class="line"><span class="comment">// arr[10]: 10</span></span><br><span class="line"><span class="comment">// arr[11]: 11</span></span><br><span class="line"><span class="comment">// arr[12]: 12</span></span><br><span class="line"><span class="comment">// arr[13]: 13</span></span><br><span class="line"><span class="comment">// arr[14]: 14</span></span><br><span class="line"><span class="comment">// arr[15]: 15</span></span><br><span class="line"><span class="comment">// arr[16]: 16</span></span><br><span class="line"><span class="comment">// arr[17]: 17</span></span><br><span class="line"><span class="comment">// arr[18]: 18</span></span><br><span class="line"><span class="comment">// arr[19]: 19</span></span><br><span class="line"><span class="comment">// arr[20]: 20</span></span><br><span class="line"><span class="comment">// arr[21]: 21</span></span><br><span class="line"><span class="comment">// arr[22]: 22</span></span><br><span class="line"><span class="comment">// arr[23]: 23</span></span><br><span class="line"><span class="comment">// arr[24]: 24</span></span><br><span class="line"><span class="comment">// arr[25]: 25</span></span><br><span class="line"><span class="comment">// arr[26]: 26</span></span><br><span class="line"><span class="comment">// arr[27]: 27</span></span><br><span class="line"><span class="comment">// arr[28]: 28</span></span><br><span class="line"><span class="comment">// arr[29]: 29</span></span><br><span class="line"><span class="comment">// arr[30]: 30</span></span><br><span class="line"><span class="comment">// arr[31]: 31</span></span><br></pre></td></tr></table></figure>

<p>如 malloc 一样，可以用 cudaMalloc 配合 n * sizeof(int)，分配一个大小为 n 的整型数组。这样就会有 n 个连续的 int 数据排列在内存中，而 arr 则是指向其起始地址。然后把 arr 指针传入 kernel，即可在里面用 arr[i] 访问它的第 i 个元素。</p>
<p>因为我们用的统一内存(managed)，所以同步以后 CPU 也可以直接读取。</p>
<h3 id="多个线程并行赋值"><a href="#多个线程并行赋值" class="headerlink" title="多个线程并行赋值"></a>多个线程并行赋值</h3><p>刚刚的 for 循环是串行的，我们可以把线程数量调为 n，然后用 threadIdx.x 作为 i 索引。这样就实现了，每个线程负责给数组中一个元素的赋值。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> i = threadIdx.x;	<span class="comment">// 每个线程赋值一个元素</span></span><br><span class="line">  arr[i] = i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">32</span>;</span><br><span class="line">  <span class="type">int</span> *arr;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;arr, n * <span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, n&gt;&gt;&gt;(arr, n);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;arr[%d]: %d\n&quot;</span>, i, arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">cudaFree</span>(arr);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// arr[0]: 0</span></span><br><span class="line"><span class="comment">// arr[1]: 1</span></span><br><span class="line"><span class="comment">// arr[2]: 2</span></span><br><span class="line"><span class="comment">// arr[3]: 3</span></span><br><span class="line"><span class="comment">// arr[4]: 4</span></span><br><span class="line"><span class="comment">// arr[5]: 5</span></span><br><span class="line"><span class="comment">// arr[6]: 6</span></span><br><span class="line"><span class="comment">// arr[7]: 7</span></span><br><span class="line"><span class="comment">// arr[8]: 8</span></span><br><span class="line"><span class="comment">// arr[9]: 9</span></span><br><span class="line"><span class="comment">// arr[10]: 10</span></span><br><span class="line"><span class="comment">// arr[11]: 11</span></span><br><span class="line"><span class="comment">// arr[12]: 12</span></span><br><span class="line"><span class="comment">// arr[13]: 13</span></span><br><span class="line"><span class="comment">// arr[14]: 14</span></span><br><span class="line"><span class="comment">// arr[15]: 15</span></span><br><span class="line"><span class="comment">// arr[16]: 16</span></span><br><span class="line"><span class="comment">// arr[17]: 17</span></span><br><span class="line"><span class="comment">// arr[18]: 18</span></span><br><span class="line"><span class="comment">// arr[19]: 19</span></span><br><span class="line"><span class="comment">// arr[20]: 20</span></span><br><span class="line"><span class="comment">// arr[21]: 21</span></span><br><span class="line"><span class="comment">// arr[22]: 22</span></span><br><span class="line"><span class="comment">// arr[23]: 23</span></span><br><span class="line"><span class="comment">// arr[24]: 24</span></span><br><span class="line"><span class="comment">// arr[25]: 25</span></span><br><span class="line"><span class="comment">// arr[26]: 26</span></span><br><span class="line"><span class="comment">// arr[27]: 27</span></span><br><span class="line"><span class="comment">// arr[28]: 28</span></span><br><span class="line"><span class="comment">// arr[29]: 29</span></span><br><span class="line"><span class="comment">// arr[30]: 30</span></span><br><span class="line"><span class="comment">// arr[31]: 31</span></span><br></pre></td></tr></table></figure>

<h3 id="小技巧：网格跨步循环（grid-stride-loop）"><a href="#小技巧：网格跨步循环（grid-stride-loop）" class="headerlink" title="小技巧：网格跨步循环（grid-stride loop）"></a>小技巧：网格跨步循环（grid-stride loop）</h3><p>需要注意的是，GPU上虽然可以启动成千上万个线程，但是每个板块上的线程数量是有限的。</p>
<p>在大多数现代CUDA支持的GPU上，<code>blockDim</code>的最大值通常是：</p>
<ul>
<li>每个维度的最大线程数：1024个线程。</li>
<li>每个线程块的总线程数：最多可以有1024个线程（即<code>blockDim.x</code>、<code>blockDim.y</code>、<code>blockDim.z</code>的乘积最多为1024）。(从这里也可以隐约感觉到CUDA虽然以三个维度组织线程管理，但在硬件实现上并不区分)</li>
</ul>
<p>因此，如果数组很大的话，我们不能直接在一个板块上启动足够的线程，即<code>&lt;&lt;&lt; g , b&gt;&gt;&gt;</code>中的b不能太大。</p>
<p>启动多个板块的话，我们就可以通过下面的操作实现网格跨步循环：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = threadIdx.x; i &lt; n; i += blockDim.x) &#123;	<span class="comment">// 自增一个板块的大小</span></span><br><span class="line">    arr[i] = i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">7</span>;</span><br><span class="line">  <span class="type">int</span> *arr;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;arr, n * <span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line"></span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">4</span>&gt;&gt;&gt;(arr, n);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;arr[%d]: %d\n&quot;</span>, i, arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(arr);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// arr[0]: 0</span></span><br><span class="line"><span class="comment">// arr[1]: 1</span></span><br><span class="line"><span class="comment">// arr[2]: 2</span></span><br><span class="line"><span class="comment">// arr[3]: 3</span></span><br><span class="line"><span class="comment">// arr[4]: 4</span></span><br><span class="line"><span class="comment">// arr[5]: 5</span></span><br><span class="line"><span class="comment">// arr[6]: 6</span></span><br></pre></td></tr></table></figure>

<p>无论调用者指定了多少个线程（blockDim），都能自动根据给定的 n 区间循环，不会越界，也不会漏掉几个元素。</p>
<p>这样一个 for 循环非常符合 CPU 上常见的 parallel for 的习惯，又能自动匹配不同的 blockDim，看起来非常方便。</p>
<p><strong>补充：</strong></p>
<ul>
<li>可以通过<code>cudaDeviceProp</code>结构中的<code>maxThreadsPerBlock</code>、<code>maxThreadsDim</code>来查询具体的硬件限制。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cppCopy codecudaDeviceProp prop;</span><br><span class="line"><span class="built_in">cudaGetDeviceProperties</span>(&amp;prop, device_id);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;Max threads per block: %d\n&quot;</span>, prop.maxThreadsPerBlock);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;Max thread block dimensions: (%d, %d, %d)\n&quot;</span>, prop.maxThreadsDim[<span class="number">0</span>], prop.maxThreadsDim[<span class="number">1</span>], prop.maxThreadsDim[<span class="number">2</span>]);</span><br></pre></td></tr></table></figure>

<ul>
<li>这些限制是为了保证GPU的硬件能够高效地调度和执行线程。</li>
</ul>
<h3 id="从线程到板块"><a href="#从线程到板块" class="headerlink" title="从线程到板块"></a>从线程到板块</h3><p>核函数内部，用之前说到的 blockDim.x + blockIdx.x + threadIdx.x 来获取线程在整个网格中编号。</p>
<p>外部调用者，则是根据不同的 n 决定板块的数量（gridDim），而每个板块具有的线程数量（blockDim）则是固定的 128。</p>
<p>因此，我们可以用 n &#x2F; 128 作为 gridDim，这样总的线程数刚好的 n，实现了每个线程负责处理一个元素。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">  arr[i] = i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  <span class="type">int</span> *arr;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;arr, n * <span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> nthreads = <span class="number">128</span>;</span><br><span class="line">  <span class="type">int</span> nblocks = n / nthreads;</span><br><span class="line">  kernel&lt;&lt;&lt;nblocks, nthreads&gt;&gt;&gt;(arr, n);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;arr[%d]: %d\n&quot;</span>, i, arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(arr);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// arr[0]: 0</span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="comment">// arr[65534]: 65534</span></span><br><span class="line"><span class="comment">// arr[65535]: 65535</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="边角料难题"><a href="#边角料难题" class="headerlink" title="边角料难题"></a>边角料难题</h3><p>但这样的话，n 只能是的 128 的整数倍，如果不是就会漏掉最后几个元素。</p>
<p>主要是 C 语言的整数除法 n &#x2F; nthreads，它是向下取整的，比如 7 &#x2F; 4 &#x3D; 1。</p>
<p>比如 n 为 65535，那么最后 127 个元素是没有赋值的。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">  arr[i] = i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65535</span>;</span><br><span class="line">  <span class="type">int</span> *arr;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;arr, n * <span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> nthreads = <span class="number">128</span>;</span><br><span class="line">  <span class="type">int</span> nblocks = n / nthreads;</span><br><span class="line">  kernel&lt;&lt;&lt;nblocks, nthreads&gt;&gt;&gt;(arr, n);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;arr[%d]: %d\n&quot;</span>, i, arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(arr);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/Clip_2024-11-05_23-23-31.png" class="" title="Clip_2024-11-05_23-23-31">

<h3 id="解决边角料难题"><a href="#解决边角料难题" class="headerlink" title="解决边角料难题"></a>解决边角料难题</h3><p>解决方法就是：采用向上取整的除法。</p>
<p>可是 C 语言好像没有向上整除的除法这个运算符？没关系，用这个式子即可：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(n + nthreads - <span class="number">1</span>) / nthreads</span><br></pre></td></tr></table></figure>

<p>例如：(7 + 3) &#x2F; 4 &#x3D; 2，(8 + 3 &#x2F; 4) &#x3D; 2。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">  <span class="keyword">if</span> (i &gt;= n) <span class="keyword">return</span>;  <span class="comment">// 防止越界，注意这里是 &#x27;&gt;=&#x27;</span></span><br><span class="line">  arr[i] = i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65535</span>;</span><br><span class="line">  <span class="type">int</span> *arr;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;arr, n * <span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> nthreads = <span class="number">128</span>;</span><br><span class="line">  <span class="type">int</span> nblocks =</span><br><span class="line">      (n + nthreads - <span class="number">1</span>) / nthreads;  <span class="comment">// 向上取整 (n + nthreads - 1) / nthreads</span></span><br><span class="line">  kernel&lt;&lt;&lt;nblocks, nthreads&gt;&gt;&gt;(arr, n);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;arr[%d]: %d\n&quot;</span>, i, arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(arr);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于向上取整，这样会多出来一些线程，因此要在 kernel 内<strong>判断</strong>当前 i 是否超过了 n，如果超过就要提前退出，防止越界。</p>
<h3 id="网格跨步循环：应用于线程与板块一起的情况"><a href="#网格跨步循环：应用于线程与板块一起的情况" class="headerlink" title="网格跨步循环：应用于线程与板块一起的情况"></a>网格跨步循环：应用于线程与板块一起的情况</h3><p>解决边角料问题的另一种方法是完整的跨步循环操作：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;  <span class="comment">// 跨步访问，i &lt; n防止了越界访问</span></span><br><span class="line">    arr[i] = i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  <span class="type">int</span> *arr;</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;arr, n * <span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line"></span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">32</span>, <span class="number">128</span>&gt;&gt;&gt;(arr, n);	<span class="comment">// 每个线程处理大约 n/4096 = 16个元素</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// int nthreads = 128;</span></span><br><span class="line"><span class="comment">// int nblocks = (n + nthreads - 1) / nthreads;  // 动态计算线程块数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// kernel&lt;&lt;&lt;nblocks, nthreads&gt;&gt;&gt;(arr, n);</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;arr[%d]: %d\n&quot;</span>, i, arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(arr);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>网格跨步循环实际上本来是这样，利用扁平化的线程数量和线程编号实现动态大小。</p>
<p>同样，无论调用者指定每个板块多少线程（blockDim），总共多少板块（gridDim）。都能自动根据给定的 n 区间循环，不会越界，也不会漏掉几个元素。</p>
<p>这样一个 for 循环非常符合 CPU 上常见的 parallel for 的习惯，又能自动匹配不同的 blockDim 和 gridDim，看起来非常方便。</p>
<p>上面的核函数可以这样拆开，会方便理解：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x;	<span class="comment">// 当前线程的全局id</span></span><br><span class="line">  <span class="type">int</span> stride = gridDim.x * blockDim.x; <span class="comment">// 块数量 * 每个块的线程数 = 启动的总线程数 = 步长</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 遍历数组中的每个元素，按跨步方式处理</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> idx = i; idx &lt; n; idx += stride) &#123;	<span class="comment">// &lt; n防止越界访问</span></span><br><span class="line">    arr[idx] = idx;  <span class="comment">// 处理数据</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="举例解释："><a href="#举例解释：" class="headerlink" title="举例解释："></a><strong>举例解释：</strong></h3><p>假设我们有以下配置：</p>
<ul>
<li><p>数组 <code>arr</code> 的大小为 <code>n = 65536</code>，即包含 65536 个元素。</p>
</li>
<li><p>使用 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel&lt;&lt;&lt;32, 128&gt;&gt;&gt;(arr, n);</span><br></pre></td></tr></table></figure>

<p> 启动 CUDA 核函数。</p>
<ul>
<li><code>gridDim.x = 32</code>，表示线程网格中有 32 个线程块（blocks）。</li>
<li><code>blockDim.x = 128</code>，表示每个线程块中有 128 个线程。</li>
<li>因此，总线程数为 <code>32 * 128 = 4096</code> 个线程。</li>
</ul>
</li>
<li><p>每个线程都将处理一个不同的数组元素，且使用跨步访问（stride）来分配任务。</p>
</li>
</ul>
<ol>
<li><strong>线程计算公式</strong></li>
</ol>
<p>每个线程的索引 <code>i</code> 由以下公式计算：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">i = blockDim.x * blockIdx.x + threadIdx.x;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>blockIdx.x</code> 是线程块的索引。</li>
<li><code>threadIdx.x</code> 是线程块内的线程索引。</li>
<li><code>blockDim.x</code> 是每个线程块的线程数。</li>
</ul>
<p>例如：</p>
<ul>
<li><code>blockIdx.x = 0</code> 表示第一个线程块。</li>
<li><code>threadIdx.x = 0</code> 表示第一个线程。</li>
<li>因此，<code>i = 128 * 0 + 0 = 0</code>，第一个线程处理索引 <code>i = 0</code></li>
</ul>
<ol start="2">
<li><strong>跨步访问(stride)</strong></li>
</ol>
<p>跨步访问是通过增加 <code>i += stride</code> 来实现的，其中 <code>stride</code> 是线程网格中所有线程的总数。对于本例：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> stride = gridDim.x * blockDim.x;  <span class="comment">// 32 * 128 = 4096</span></span><br></pre></td></tr></table></figure>

<p>这里的 <code>stride</code> 计算为 <code>4096</code>，表示每个线程在数组中跨步的大小。也就是说，每个线程处理的数据并不是相邻的，而是间隔 4096 个元素。</p>
<ol start="3">
<li><strong>线程的工作范围</strong></li>
</ol>
<p>每个线程的工作由一个循环实现，使用跨步访问来遍历数组：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n; i += stride) &#123;</span><br><span class="line">  arr[i] = i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>i = blockDim.x * blockIdx.x + threadIdx.x</code> 是线程的起始索引。</li>
<li><code>i += stride</code> 确保线程按步长 <code>4096</code> 遍历数组。</li>
</ul>
<ol start="4">
<li><strong>每个线程块的处理</strong></li>
</ol>
<p>假设我们有 32 个线程块，每个线程块有 128 个线程。那么对于每个线程块和线程的组合，线程索引 <code>i</code> 会依次进行计算。</p>
<ul>
<li><p><strong>第一个线程块</strong>（<code>blockIdx.x = 0</code>）:</p>
<ul>
<li>线程 <code>threadIdx.x = 0</code>：<code>i = 128 * 0 + 0 = 0</code>，处理 <code>arr[0]</code>。</li>
<li>线程 <code>threadIdx.x = 1</code>：<code>i = 128 * 0 + 1 = 1</code>，处理 <code>arr[1]</code>。</li>
<li>线程 <code>threadIdx.x = 127</code>：<code>i = 128 * 0 + 127 = 127</code>，处理 <code>arr[127]</code>。</li>
</ul>
</li>
<li><p><strong>第二个线程块</strong>（<code>blockIdx.x = 1</code>）:</p>
<ul>
<li>线程 <code>threadIdx.x = 0</code>：<code>i = 128 * 1 + 0 = 128</code>，处理 <code>arr[128]</code>。</li>
<li>线程 <code>threadIdx.x = 127</code>：<code>i = 128 * 1 + 127 = 255</code>，处理 <code>arr[255]</code>。</li>
</ul>
</li>
<li><p><strong>第32个线程块</strong>（<code>blockIdx.x = 31</code>）：</p>
<ul>
<li>线程 <code>threadIdx.x = 0</code>：<code>i = 128 * 31 + 0 = 3968</code>，处理 <code>arr[3968]</code>。</li>
<li>线程 <code>threadIdx.x = 127</code>：<code>i = 128 * 31 + 127 = 128</code>，处理 <code>arr[4095]</code>。</li>
</ul>
</li>
</ul>
<p>这只是第一轮循环的内容，每次循环上面的每个线程都会跳过步长(4096)个元素。最终循环16轮</p>
<ol start="5">
<li><strong>分析第16轮的情况：</strong></li>
</ol>
<ul>
<li><strong>第一个线程块</strong>（<code>blockIdx.x = 0</code>）:<ul>
<li>线程 <code>threadIdx.x = 0</code>*<ul>
<li>索引为 <code>i = 0 + 15 * 4096 = 61440</code>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>这里我们计算一下：<code>65535 - 61440 = 4095</code>可以看出我们确实不需要再跳一次4096了</p>
<ul>
<li>第32个线程块（<code>blockIdx.x = 31</code>）：<ul>
<li>线程 <code>threadIdx.x = 127</code><ul>
<li>索引为 <code>i = (128 * 31 + 127) + 15 * 4096 = 65535</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>终于，我们看到第16轮循环时，最后一个线程块的最后一个线程刚好访问到第65535个元素！</p>
<h2 id="第四章：C-封装GPU上的数组"><a href="#第四章：C-封装GPU上的数组" class="headerlink" title="第四章：C++封装GPU上的数组"></a>第四章：C++封装GPU上的数组</h2><h3 id="std-vector的秘密：第二模板参数"><a href="#std-vector的秘密：第二模板参数" class="headerlink" title="std::vector的秘密：第二模板参数"></a>std::vector的秘密：第二模板参数</h3><p><strong>你知道吗？</strong>std::vector 作为模板类，其实有两个模板参数：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;T, AllocatorT&gt;</span><br></pre></td></tr></table></figure>

<p>那为什么我们平时只用了 std::vector<T> 呢？因为第二个参数默认是 std::allocator<T>。</p>
<p>也就是 std::vector<T> 等价于 std::vector&lt;T, std::allocator<T>&gt;。</p>
<p>std::allocator<T> 的功能是负责分配和释放内存，初始化 T 对象等等。</p>
<p>它具有如下几个成员函数：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">T *<span class="title">allocate</span><span class="params">(<span class="type">size_t</span> n)</span>	<span class="comment">// 分配长度为n，类型为T的数组，返回其起始地址</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(T *p, <span class="type">size_t</span> n)</span>	<span class="comment">// 释放长度为n，起始地址为p，类型为T的数组</span></span></span><br></pre></td></tr></table></figure>

<h3 id="抽象的-std-allocator-接口"><a href="#抽象的-std-allocator-接口" class="headerlink" title="抽象的 std::allocator 接口"></a>抽象的 std::allocator 接口</h3><p>vector 会调用 std::allocator<T> 的 allocate&#x2F;deallocate 成员函数，他又会去调用标准库的 malloc&#x2F;free 分配和释放内存空间（即他分配是的 CPU 内存）。</p>
<p>我们可以自己定义一个和 std::allocator<T> 一样具有 allocate&#x2F;deallocate 成员函数的类，这样就可以“骗过”vector，让他不是在 CPU 内存中分配，而是在 CUDA 的统一内存(managed)上分配。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CudaAllocator</span> &#123;</span><br><span class="line">  <span class="keyword">using</span> value_type = T;</span><br><span class="line"></span><br><span class="line">  <span class="function">T *<span class="title">allocate</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    T *ptr = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;ptr, size * <span class="built_in">sizeof</span>(T)));</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(T *ptr, <span class="type">size_t</span> size = <span class="number">0</span>)</span> </span>&#123; <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaFree</span>(ptr)); &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    arr[i] = i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);  <span class="comment">// 第二参数是自定义的分配器</span></span><br><span class="line"></span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">32</span>, <span class="number">128</span>&gt;&gt;&gt;(arr.<span class="built_in">data</span>(), n);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;arr[%d]: %d\n&quot;</span>, i, arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实际上这种“骗”来魔改类内部行为的操作，正是现代 C++ 的 concept 思想所在。因此替换 allocator 实际上是标准库允许的，因为他提升了标准库的泛用性。</p>
<h3 id="进一步：避免初始化为0"><a href="#进一步：避免初始化为0" class="headerlink" title="进一步：避免初始化为0"></a>进一步：避免初始化为0</h3><p>vector 在初始化的时候（或是之后 resize 的时候）会调用所有元素的无参构造函数，对 int 类型来说就是零初始化。然而这个初始化会是在 CPU 上做的，因此我们需要禁用他。</p>
<p>可以通过给 allocator 添加 construct 成员函数，来魔改 vector 对元素的构造。默认情况下他可以有任意多个参数，而如果没有参数则说明是无参构造函数。</p>
<p>因此我们只需要判断是不是有参数，然后是不是传统的 C 语言类型（plain-old-data），如果是，则跳过其无参构造，从而避免在 CPU 上低效的零初始化。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CudaAllocator</span> &#123;</span><br><span class="line">  <span class="keyword">using</span> value_type = T;</span><br><span class="line"></span><br><span class="line">  <span class="function">T *<span class="title">allocate</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    T *ptr = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;ptr, size * <span class="built_in">sizeof</span>(T)));</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(T *ptr, <span class="type">size_t</span> size = <span class="number">0</span>)</span> </span>&#123; <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaFree</span>(ptr)); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">class</span>... Args&gt;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">construct</span><span class="params">(T *p, Args &amp;&amp;...args)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(!(<span class="keyword">sizeof</span>...(Args) == <span class="number">0</span> &amp;&amp; std::is_pod_v&lt;T&gt;))</span></span></span><br><span class="line"><span class="function">      ::<span class="title">new</span> <span class="params">((<span class="type">void</span> *)p)</span> <span class="title">T</span><span class="params">(std::forward&lt;Args&gt;(args)...)</span></span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    arr[i] = i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line"></span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">32</span>, <span class="number">128</span>&gt;&gt;&gt;(arr.<span class="built_in">data</span>(), n);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;arr[%d]: %d\n&quot;</span>, i, arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>解释一下construct函数的写法：</li>
<li><code>if constexpr (条件)</code>是 C++17的语法，根据条件在编译期选择性编译不同的代码</li>
<li><code>sizeof...(Args) == 0 &amp;&amp; std::is_pod_v&lt;T&gt;</code>：判断参数包 <code>Args</code> 是否为空（没有构造参数）并且类型 <code>T</code> 是否是 POD 类型。</li>
<li><code>::new</code> 是一种使用显式地址来调用构造函数的语法，可以指定对象应该在内存的哪个位置进行构造。</li>
</ul>
<h3 id="进一步：核函数可以是一个模板函数"><a href="#进一步：核函数可以是一个模板函数" class="headerlink" title="进一步：核函数可以是一个模板函数"></a>进一步：核函数可以是一个模板函数</h3><p>刚刚说过 CUDA 的优势在于对 C++ 的完全支持。所以 <code>__global__</code> 修饰的核函数自然也是可以为模板函数的。</p>
<p>调用模板时一样可以用自动参数类型推导，如有手动指定的模板参数（单尖括号）请放在三重尖括号的前面。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CudaAllocator</span> &#123;</span><br><span class="line">  <span class="keyword">using</span> value_type = T;</span><br><span class="line"></span><br><span class="line">  <span class="function">T *<span class="title">allocate</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    T *ptr = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;ptr, size * <span class="built_in">sizeof</span>(T)));</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(T *ptr, <span class="type">size_t</span> size = <span class="number">0</span>)</span> </span>&#123; <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaFree</span>(ptr)); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">class</span>... Args&gt;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">construct</span><span class="params">(T *p, Args &amp;&amp;...args)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(!(<span class="keyword">sizeof</span>...(Args) == <span class="number">0</span> &amp;&amp; std::is_pod_v&lt;T&gt;))</span></span></span><br><span class="line"><span class="function">      ::<span class="title">new</span> <span class="params">((<span class="type">void</span> *)p)</span> <span class="title">T</span><span class="params">(std::forward&lt;Args&gt;(args)...)</span></span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">int</span> N, <span class="keyword">class</span> <span class="title class_">T</span>&gt;  <span class="comment">// 核函数模板</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(T *arr)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; N;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    arr[i] = i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">constexpr</span> <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line"></span><br><span class="line">  kernel&lt;n&gt;&lt;&lt;&lt;<span class="number">32</span>, <span class="number">128</span>&gt;&gt;&gt;(arr.<span class="built_in">data</span>());	<span class="comment">// 手动指定模板参数 &lt;&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;arr[%d]: %d\n&quot;</span>, i, arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="进一步：核函数可以接受函子-functor-，实现函数式编程"><a href="#进一步：核函数可以接受函子-functor-，实现函数式编程" class="headerlink" title="进一步：核函数可以接受函子(functor)，实现函数式编程"></a>进一步：核函数可以接受函子(functor)，实现函数式编程</h3><ul>
<li>在 C++ 中，<strong>函子</strong>（Functor）是一个可以像函数一样<strong>被调用的对象</strong>。也就是说，函子是一个重载了 <code>operator()</code> 的类或结构体的实例</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">MyFunctor</span> &#123;  <span class="comment">// 函数对象</span></span><br><span class="line">  <span class="function">__device__ <span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">int</span> i)</span> <span class="type">const</span> </span>&#123; <span class="built_in">printf</span>(<span class="string">&quot;number %d\n&quot;</span>, i); &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line"></span><br><span class="line">  parallel_for&lt;&lt;&lt;<span class="number">32</span>, <span class="number">128</span>&gt;&gt;&gt;(n, MyFunctor&#123;&#125;);  <span class="comment">// 调用一个函数对象（函子functor）</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>不过要注意三点：</p>
<ol>
<li><p>这里的 Func 不可以是 Func const &amp;，那样会变成一个指向 CPU 内存地址的指针，从而出错。所以 CPU 向 GPU 的传参必须按值传。</p>
</li>
<li><p>做参数的这个函数必须是一个有着成员函数 operator() 的类型，即 functor 类。而不能是独立的函数，否则报错。</p>
</li>
<li><p>这个函数必须标记为 <code>__device__</code>，即 GPU 上的函数，否则会变成 CPU 上的函数。</p>
</li>
</ol>
<h3 id="进一步：函子可以是-lambda-表达式"><a href="#进一步：函子可以是-lambda-表达式" class="headerlink" title="进一步：函子可以是 lambda 表达式"></a>进一步：函子可以是 lambda 表达式</h3><p>lambda这么方便，CUDA当然也要支持，只需要开启 <code>--extended-lambda</code>选项</p>
<p>接下来就可以直接写 lambda 表达式，不过必须在 [] 后，() 前，插入 <code>__device__</code> 修饰符。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[] __device__ () &#123; &#125;</span><br></pre></td></tr></table></figure>

<p>为了只对 .cu 文件开启这个开关，可以用 CMake 的生成器表达式，限制 flag 只对 CUDA 源码生效，这样可以混合其他 .cpp 文件也不会发生 gcc 报错的情况了。。</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_executable</span>(main main.cu)</span><br><span class="line"><span class="keyword">target_include_directories</span>(main PUBLIC ../../<span class="keyword">include</span>)</span><br><span class="line"><span class="keyword">target_compile_options</span>(main PUBLIC $&lt;$&lt;COMPILE_LANGUAGE:CUDA&gt;:--extended-lambda&gt;)	<span class="comment"># 开启选项</span></span><br></pre></td></tr></table></figure>

<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/image-20241106224704198.png" class="" title="image-20241106224704198">

<h3 id="怎样捕获外部变量？"><a href="#怎样捕获外部变量？" class="headerlink" title="怎样捕获外部变量？"></a>怎样捕获外部变量？</h3><p>lambda表达式在CUDA上要怎样捕获变量呢？</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CudaAllocator</span> &#123;</span><br><span class="line">  <span class="keyword">using</span> value_type = T;</span><br><span class="line"></span><br><span class="line">  <span class="function">T *<span class="title">allocate</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    T *ptr = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;ptr, size * <span class="built_in">sizeof</span>(T)));</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(T *ptr, <span class="type">size_t</span> size = <span class="number">0</span>)</span> </span>&#123; <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaFree</span>(ptr)); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">class</span>... Args&gt;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">construct</span><span class="params">(T *p, Args &amp;&amp;...args)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(!(<span class="keyword">sizeof</span>...(Args) == <span class="number">0</span> &amp;&amp; std::is_pod_v&lt;T&gt;))</span></span></span><br><span class="line"><span class="function">      ::<span class="title">new</span> <span class="params">((<span class="type">void</span> *)p)</span> <span class="title">T</span><span class="params">(std::forward&lt;Args&gt;(args)...)</span></span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line"></span><br><span class="line">  parallel_for&lt;&lt;&lt;<span class="number">32</span>, <span class="number">128</span>&gt;&gt;&gt;(n, [&amp;] __device__(<span class="type">int</span> i) &#123; arr[i] = i; &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果试图用 <code>[&amp;]</code> 捕获变量是会出错的，毕竟这时候捕获到的是堆栈（<strong>CPU</strong>内存）上的变量 arr 本身，而不是 arr 所指向的内存地址（<strong>GPU</strong>内存）。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/Clip_2024-11-06_22-55-27.png" class="" title="Clip_2024-11-06_22-55-27">

<p>你可能会想，是不是可以用 [&#x3D;] 按值捕获，这样捕获到的就是指针了吧？</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CudaAllocator</span> &#123;</span><br><span class="line">  <span class="keyword">using</span> value_type = T;</span><br><span class="line"></span><br><span class="line">  <span class="function">T *<span class="title">allocate</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    T *ptr = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;ptr, size * <span class="built_in">sizeof</span>(T)));</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(T *ptr, <span class="type">size_t</span> size = <span class="number">0</span>)</span> </span>&#123; <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaFree</span>(ptr)); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">class</span>... Args&gt;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">construct</span><span class="params">(T *p, Args &amp;&amp;...args)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(!(<span class="keyword">sizeof</span>...(Args) == <span class="number">0</span> &amp;&amp; std::is_pod_v&lt;T&gt;))</span></span></span><br><span class="line"><span class="function">      ::<span class="title">new</span> <span class="params">((<span class="type">void</span> *)p)</span> <span class="title">T</span><span class="params">(std::forward&lt;Args&gt;(args)...)</span></span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line"></span><br><span class="line">  parallel_for&lt;&lt;&lt;<span class="number">32</span>, <span class="number">128</span>&gt;&gt;&gt;(n, [=] __device__(<span class="type">int</span> i) &#123; arr[i] = i; &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>错了，不要忘了我们在STL中说过，vector 的拷贝是深拷贝（绝大多数C++类都是深拷贝，除了智能指针和原始指针）。这样只会把 vector 整个地拷贝到 GPU 上！而不是浅拷贝其起始地址指针。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/Clip_2024-11-06_22-56-27.png" class="" title="Clip_2024-11-06_22-56-27">

<p><strong>正确的做法</strong>是，首先获取<code>arr.data()</code> 的值到 arr_data 变量，然后用 [&#x3D;] 按值捕获 arr_data，函数体里面也通过 arr_data 来访问 arr。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CudaAllocator</span> &#123;</span><br><span class="line">  <span class="keyword">using</span> value_type = T;</span><br><span class="line"></span><br><span class="line">  <span class="function">T *<span class="title">allocate</span><span class="params">(<span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    T *ptr = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaMallocManaged</span>(&amp;ptr, size * <span class="built_in">sizeof</span>(T)));</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">deallocate</span><span class="params">(T *ptr, <span class="type">size_t</span> size = <span class="number">0</span>)</span> </span>&#123; <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaFree</span>(ptr)); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">class</span>... Args&gt;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">construct</span><span class="params">(T *p, Args &amp;&amp;...args)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(!(<span class="keyword">sizeof</span>...(Args) == <span class="number">0</span> &amp;&amp; std::is_pod_v&lt;T&gt;))</span></span></span><br><span class="line"><span class="function">      ::<span class="title">new</span> <span class="params">((<span class="type">void</span> *)p)</span> <span class="title">T</span><span class="params">(std::forward&lt;Args&gt;(args)...)</span></span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> *arr_data = arr.<span class="built_in">data</span>();  <span class="comment">// 先获取指针</span></span><br><span class="line">  parallel_for&lt;&lt;&lt;<span class="number">32</span>, <span class="number">128</span>&gt;&gt;&gt;(n, [=] __device__(<span class="type">int</span> i) &#123; arr_data[i] = i; &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;arr[%d] = %d\n&quot;</span>, i, arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>为什么这样？因为 data() 返回一个起始地址的原始指针，而原始指针是浅拷贝的，所以可以拷贝到 GPU 上，让他访问。这样和之前作为核函数参数是一样的，不过是作为 Func 结构体统一传入了。</p>
<p>或者在 <code>[]</code> 里这样直接写自定义捕获的表达式也是可以的，这样就可以用同一变量名。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line"></span><br><span class="line">parallel_for&lt;&lt;&lt;<span class="number">32</span>, <span class="number">128</span>&gt;&gt;&gt;(</span><br><span class="line">    n, [arr = arr.<span class="built_in">data</span>()] __device__(<span class="type">int</span> i) &#123; arr[i] = i; &#125;);</span><br></pre></td></tr></table></figure>

<h2 id="第五章：数学运算"><a href="#第五章：数学运算" class="headerlink" title="第五章：数学运算"></a>第五章：数学运算</h2><h4 id="经典案例，并行地求-sin-值"><a href="#经典案例，并行地求-sin-值" class="headerlink" title="经典案例，并行地求 sin 值"></a>经典案例，并行地求 sin 值</h4><p><em>终于可以在GPU上干点正事了(bushi</em></p>
<p>就让我们在 GPU 上并行地计算从 sin(0) 到 sin(65535) 的值，并填入到数组 arr 中。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CudaAllocator.h&quot;</span>  <span class="comment">// 封装刚才的内存分配器</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  std::vector&lt;<span class="type">float</span>, CudaAllocator&lt;<span class="type">float</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line"></span><br><span class="line">  parallel_for&lt;&lt;&lt;<span class="number">32</span>, <span class="number">128</span>&gt;&gt;&gt;(</span><br><span class="line">      n, [arr = arr.<span class="built_in">data</span>()] __device__(<span class="type">int</span> i) &#123; arr[i] = <span class="built_in">sinf</span>(i); &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;diff %d = %f\n&quot;</span>, i, arr[i] - <span class="built_in">sinf</span>(i));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>这里为什么用 sinf 而不是 sin？</p>
</li>
<li><p>因为 sin 是 double 类型的正弦函数，而我们需要的 sinf 是 float 类型的正弦函数。</p>
</li>
<li><p>可不要偷懒少打一个 f 哦，否则计算过程需要对数据类型进行转换，影响性能。</p>
</li>
</ul>
<p>完成同步之后，和 CPU 算出来的比较差值，看看 GPU 算的是否准确无误，从右边的输出可以看到基本是一致的。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/Clip_2024-11-06_23-25-46.png" class="" title="Clip_2024-11-06_23-25-46">

<h3 id="测试一下时间"><a href="#测试一下时间" class="headerlink" title="测试一下时间"></a>测试一下时间</h3><p>提供一个小工具：ticktock.h</p>
<p>可以用来打印 CPU 和 GPU的用时</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> once</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;chrono&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> __ycm__</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TICK(x) auto bench_##x = std::chrono::steady_clock::now();</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TOCK(x)                                                     \</span></span><br><span class="line"><span class="meta">  printf(<span class="string">&quot;%s: %lfs\n&quot;</span>, #x,                                          \</span></span><br><span class="line"><span class="meta">         std::chrono::duration_cast<span class="string">&lt;std::chrono::duration&lt;double&gt;</span>&gt;( \</span></span><br><span class="line"><span class="meta">             std::chrono::steady_clock::now() - bench_##x)          \</span></span><br><span class="line"><span class="meta">             .count());</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TICK(x)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TOCK(x)</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>

<p><strong>注意</strong>，这里一定要把 TOCK 放到同步之后。原因之前说过，因为对 GPU 核函数的调用是异步的，只有 cudaDeviceSynchronize() 以后才真正完成执行，才能算出真的时间。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CudaAllocator.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;ticktock.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">1</span> &lt;&lt; <span class="number">25</span>;</span><br><span class="line">  std::vector&lt;<span class="type">float</span>, CudaAllocator&lt;<span class="type">float</span>&gt;&gt; <span class="built_in">gpu</span>(n);</span><br><span class="line">  <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">cpu</span><span class="params">(n)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">TICK</span>(cpu_sinf);  <span class="comment">// cpu开始时间</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    cpu[i] = <span class="built_in">sinf</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">TOCK</span>(cpu_sinf);  <span class="comment">// cpu结束时间</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">TICK</span>(gpu_sinf);  <span class="comment">// gpu开始时间</span></span><br><span class="line">  parallel_for&lt;&lt;&lt;n / <span class="number">512</span>, <span class="number">128</span>&gt;&gt;&gt;(</span><br><span class="line">      n, [gpu = gpu.<span class="built_in">data</span>()] __device__(<span class="type">int</span> i) &#123; gpu[i] = <span class="built_in">sinf</span>(i); &#125;);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">TOCK</span>(gpu_sinf);  <span class="comment">// gpu结束时间 注意放在GPU同步之后</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// for (int i = 0; i &lt; n; i++) &#123;</span></span><br><span class="line">  <span class="comment">// printf(&quot;diff %d = %f\n&quot;, i, gpu[i] - cpu[i]);</span></span><br><span class="line">  <span class="comment">//&#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// cpu_sinf: 0.119689s</span></span><br><span class="line"><span class="comment">// gpu_sinf : 0.034462s</span></span><br></pre></td></tr></table></figure>

<p>查看结果，发现 GPU 比 CPU 快了很多，这是当然的。</p>
<ul>
<li>有时候可能出现GPU比CPU慢很多，或者两次运行GPU速度差距很大</li>
<li>这是因为GPU初始化需要准备一些资源，第二次启动时就不需要了</li>
<li>所以有时会看到，大佬会先空调用一下GPU，之后再执行任务。</li>
</ul>
<p>适当调整板块数量 gridDim 和每板块的线程数量 blockDim，还可以更快一些。可以自己调调看，这里我们就不浪费篇幅了。</p>
<p>顺便一提，这样的数学函数还有 ：</p>
<table>
<thead>
<tr>
<th><strong>函数</strong></th>
<th><strong>简要功能</strong></th>
</tr>
</thead>
<tbody><tr>
<td><code>sqrtf(x)</code></td>
<td>返回 <code>x</code> 的平方根。</td>
</tr>
<tr>
<td><code>rsqrtf(x)</code></td>
<td>返回 <code>x</code> 的倒数平方根，即 <code>1/sqrtf(x)</code>。</td>
</tr>
<tr>
<td><code>cbrtf(x)</code></td>
<td>返回 <code>x</code> 的立方根。</td>
</tr>
<tr>
<td><code>rcbrtf(x)</code></td>
<td>返回 <code>x</code> 的倒数立方根，即 <code>1/cbrtf(x)</code>。</td>
</tr>
<tr>
<td><code>powf(x, y)</code></td>
<td>返回 <code>x</code> 的 <code>y</code> 次幂（<code>x^y</code>）。</td>
</tr>
<tr>
<td><code>sinf(x)</code></td>
<td>返回 <code>x</code> 的正弦值，<code>x</code> 为弧度制。</td>
</tr>
<tr>
<td><code>cosf(x)</code></td>
<td>返回 <code>x</code> 的余弦值，<code>x</code> 为弧度制。</td>
</tr>
<tr>
<td><code>sinpif(x)</code></td>
<td>返回 <code>x * pi</code> 的正弦值，<code>x</code> 为倍数。</td>
</tr>
<tr>
<td><code>cospif(x)</code></td>
<td>返回 <code>x * pi</code> 的余弦值，<code>x</code> 为倍数。</td>
</tr>
<tr>
<td><code>sincosf(x)</code></td>
<td>返回一个结构体，包含 <code>x</code> 的正弦值和余弦值，<code>x</code> 为弧度制。</td>
</tr>
<tr>
<td><code>sincospif(x)</code></td>
<td>返回一个结构体，包含 <code>x * pi</code> 的正弦值和余弦值，<code>x</code> 为倍数。</td>
</tr>
<tr>
<td><code>logf(x)</code></td>
<td>返回 <code>x</code> 的自然对数（以 <code>e</code> 为底）。</td>
</tr>
<tr>
<td><code>log2f(x)</code></td>
<td>返回 <code>x</code> 的以 2 为底的对数。</td>
</tr>
<tr>
<td><code>log10f(x)</code></td>
<td>返回 <code>x</code> 的以 10 为底的对数。</td>
</tr>
<tr>
<td><code>expf(x)</code></td>
<td>返回 <code>e^x</code>，即 <code>e</code> 的 <code>x</code> 次幂。</td>
</tr>
<tr>
<td><code>exp2f(x)</code></td>
<td>返回 <code>2^x</code>，即 2 的 <code>x</code> 次幂。</td>
</tr>
<tr>
<td><code>exp10f(x)</code></td>
<td>返回 <code>10^x</code>，即 10 的 <code>x</code> 次幂。</td>
</tr>
<tr>
<td><code>tanf(x)</code></td>
<td>返回 <code>x</code> 的正切值，<code>x</code> 为弧度制。</td>
</tr>
<tr>
<td><code>atanf(x)</code></td>
<td>返回 <code>x</code> 的反正切值（<code>arctan(x)</code>），返回结果是弧度制。</td>
</tr>
<tr>
<td><code>asinf(x)</code></td>
<td>返回 <code>x</code> 的反正弦值（<code>arcsin(x)</code>），返回结果是弧度制。</td>
</tr>
<tr>
<td><code>acosf(x)</code></td>
<td>返回 <code>x</code> 的反余弦值（<code>arccos(x)</code>），返回结果是弧度制。</td>
</tr>
<tr>
<td><code>fmodf(x, y)</code></td>
<td>返回 <code>x</code> 除以 <code>y</code> 后的余数。</td>
</tr>
<tr>
<td><code>fabsf(x)</code></td>
<td>返回 <code>x</code> 的绝对值。</td>
</tr>
<tr>
<td><code>fminf(x, y)</code></td>
<td>返回 <code>x</code> 和 <code>y</code> 中的较小值。</td>
</tr>
<tr>
<td><code>fmaxf(x, y)</code></td>
<td>返回 <code>x</code> 和 <code>y</code> 中的较大值。</td>
</tr>
</tbody></table>
<p>功能总结：</p>
<ul>
<li><strong>平方根与幂</strong>：<code>sqrtf</code>、<code>rsqrtf</code>、<code>cbrtf</code>、<code>rcbrtf</code>、<code>powf</code> 等用于计算数值的平方根、倒数平方根、立方根、倒数立方根和幂。</li>
<li><strong>三角函数</strong>：<code>sinf</code>、<code>cosf</code>、<code>sinpif</code>、<code>cospif</code>、<code>sincosf</code>、<code>sincospif</code> 计算正弦、余弦、及其在 π 倍数上的变种。</li>
<li><strong>对数与指数函数</strong>：<code>logf</code>、<code>log2f</code>、<code>log10f</code>、<code>expf</code>、<code>exp2f</code>、<code>exp10f</code> 用于自然对数、以 2 或 10 为底的对数，及对应的指数运算。</li>
<li><strong>反三角函数</strong>：<code>atanf</code>、<code>asinf</code>、<code>acosf</code> 返回反正切、反正弦、反余弦函数的值。</li>
<li><strong>数学常用操作</strong>：<code>fmodf</code> 用于取余，<code>fabsf</code> 返回绝对值，<code>fminf</code> 和 <code>fmaxf</code> 用于选择最小值和最大值。</li>
</ul>
<h3 id="稍快，但不完全精确的-sinf"><a href="#稍快，但不完全精确的-sinf" class="headerlink" title="稍快，但不完全精确的 __sinf"></a>稍快，但不完全精确的 <code>__sinf</code></h3><p>两个下划线的 __sinf 是 GPU intrinstics，精度相当于 GLSL 里的那种。适合对精度要求不高，但有性能要求的图形学任务。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CudaAllocator.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;ticktock.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">1</span> &lt;&lt; <span class="number">25</span>;</span><br><span class="line">  std::vector&lt;<span class="type">float</span>, CudaAllocator&lt;<span class="type">float</span>&gt;&gt; <span class="built_in">gpu</span>(n);</span><br><span class="line">  <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">cpu</span><span class="params">(n)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">TICK</span>(cpu_sinf);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    cpu[i] = <span class="built_in">sinf</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">TOCK</span>(cpu_sinf);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">TICK</span>(gpu_sinf);</span><br><span class="line">  parallel_for&lt;&lt;&lt;n / <span class="number">512</span>, <span class="number">128</span>&gt;&gt;&gt;(</span><br><span class="line">      n, [gpu = gpu.<span class="built_in">data</span>()] __device__(<span class="type">int</span> i) &#123; gpu[i] = __sinf(i); &#125;);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">TOCK</span>(gpu_sinf);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// for (int i = 0; i &lt; n; i++) &#123;</span></span><br><span class="line">  <span class="comment">// printf(&quot;diff %d = %f\n&quot;, i, gpu[i] - cpu[i]);</span></span><br><span class="line">  <span class="comment">//&#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// cpu_sinf: 0.118834s</span></span><br><span class="line"><span class="comment">// gpu_sinf: 0.026515s</span></span><br></pre></td></tr></table></figure>

<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/Clip_2024-11-07_00-46-35.png" class="" title="Clip_2024-11-07_00-46-35">

<p>类似的低精度内建函数还有 <code>__expf</code>、<code>__logf</code>、<code>__cosf</code>、<code>__powf</code> 等.</p>
<p>另外，<code>__fdividef(x, y)</code> 是一个专门用于浮点除法的优化函数，它提供与常规除法相同的精度，且计算速度更快。然而，当 <code>y</code> 的值位于 <code>2^216</code> 到 <code>2^218</code> 之间时，可能会返回错误的结果，因此在使用时需要避免该数值范围。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/Clip_2024-11-07_00-56-06.png" class="" title="Clip_2024-11-07_00-56-06">

<h3 id="编译器选项：-use-fast-math"><a href="#编译器选项：-use-fast-math" class="headerlink" title="编译器选项：--use_fast_math"></a>编译器选项：<code>--use_fast_math</code></h3><p>启用 <code>--use_fast_math</code> 选项时，编译器会对多个数学操作进行优化以提升性能，具体包括：</p>
<ul>
<li><strong><code>sinf</code> 调用优化</strong>：所有对 <code>sinf</code> 的调用会自动替换为 <code>__sinf</code>，以使用更快的实现。</li>
<li>**<code>--ftz=true</code>**：将极小数（非规格化数，denormal）视为 0，从而避免额外的处理开销，提高运算速度。</li>
<li>**<code>--prec-div=false</code>**：降低除法运算的精度，换取更快的计算速度。</li>
<li>**<code>--prec-sqrt=false</code>**：降低平方根运算的精度，提升运算速度。</li>
<li>**<code>--fmad</code>**：启用浮点数乘加指令（FMA），将表达式 <code>a * b + c</code> 自动优化为更高效的乘加指令。此选项默认开启，因其对性能影响显著。</li>
</ul>
<p>开启 <code>--use_fast_math</code> 后，以上所有优化选项将自动启用。</p>
<h3 id="SAXPY（Scalar-A-times-X-Plus-Y）"><a href="#SAXPY（Scalar-A-times-X-Plus-Y）" class="headerlink" title="SAXPY（Scalar A times X Plus Y）"></a>SAXPY（Scalar A times X Plus Y）</h3><p>即标量 A 乘 X 加 Y</p>
<p>这是很多CUDA教科书中的“Hello, world”，我们这里也来实现一下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CudaAllocator.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  <span class="type">float</span> a = <span class="number">3.14f</span>;</span><br><span class="line">  std::vector&lt;<span class="type">float</span>, CudaAllocator&lt;<span class="type">float</span>&gt;&gt; <span class="built_in">x</span>(n);</span><br><span class="line">  std::vector&lt;<span class="type">float</span>, CudaAllocator&lt;<span class="type">float</span>&gt;&gt; <span class="built_in">y</span>(n);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    x[i] = std::<span class="built_in">rand</span>() * (<span class="number">1.f</span> / RAND_MAX);</span><br><span class="line">    y[i] = std::<span class="built_in">rand</span>() * (<span class="number">1.f</span> / RAND_MAX);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  parallel_for&lt;&lt;&lt;n / <span class="number">512</span>, <span class="number">128</span>&gt;&gt;&gt;(</span><br><span class="line">      n, [a, x = x.<span class="built_in">data</span>(), y = y.<span class="built_in">data</span>()] __device__(<span class="type">int</span> i) &#123;</span><br><span class="line">        x[i] = a * x[i] + y[i];  <span class="comment">// 乘加操作</span></span><br><span class="line">      &#125;);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;x[%d] = %f\n&quot;</span>, i, x[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="第六章：thrust库"><a href="#第六章：thrust库" class="headerlink" title="第六章：thrust库"></a>第六章：thrust库</h2><h3 id="使用-CUDA-官方提供的-thrust-universal-vector"><a href="#使用-CUDA-官方提供的-thrust-universal-vector" class="headerlink" title="使用 CUDA 官方提供的 thrust::universal_vector"></a>使用 CUDA 官方提供的 thrust::universal_vector</h3><p>虽然自己实现 CudaAllocator 很有趣，也帮助我们理解了底层原理。但是既然 CUDA 官方已经提供了 thrust 库，那就用他们的好啦。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/universal_vector.h&gt;</span>  <span class="comment">// trusth库</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  <span class="type">float</span> a = <span class="number">3.14f</span>;</span><br><span class="line">  <span class="function">thrust::universal_vector&lt;<span class="type">float</span>&gt; <span class="title">x</span><span class="params">(n)</span></span>;  <span class="comment">// 使用 thrust库的 universal_vector</span></span><br><span class="line">  <span class="function">thrust::universal_vector&lt;<span class="type">float</span>&gt; <span class="title">y</span><span class="params">(n)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    x[i] = std::<span class="built_in">rand</span>() * (<span class="number">1.f</span> / RAND_MAX);</span><br><span class="line">    y[i] = std::<span class="built_in">rand</span>() * (<span class="number">1.f</span> / RAND_MAX);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  parallel_for&lt;&lt;&lt;n / <span class="number">512</span>, <span class="number">128</span>&gt;&gt;&gt;(n, [a, x = x.<span class="built_in">data</span>(), y = y.<span class="built_in">data</span>()] __device__(</span><br><span class="line">                                        <span class="type">int</span> i) &#123; x[i] = a * x[i] + y[i]; &#125;);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;x[%d] = %f\n&quot;</span>, i, x[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>universal_vector</code> 是基于统一内存分配的，因此无论在 GPU 还是 CPU 上，数据都可以直接访问。</p>
<h3 id="使用分离的-device-vector-和-host-vector"><a href="#使用分离的-device-vector-和-host-vector" class="headerlink" title="使用分离的 device_vector 和 host_vector"></a>使用分离的 device_vector 和 host_vector</h3><p><code>device_vector</code> 在 GPU 上分配内存，而 <code>host_vector</code> 则在 CPU 上分配内存。</p>
<p>可以通过 &#x3D; 运算符在 device_vector 和 host_vector 之间拷贝数据，他会自动帮你调用 cudaMemcpy，非常智能。</p>
<p>比如这里的 <code>x_dev = x_host</code> 会将 <code>x_host</code> 中的数据复制到 GPU 上的 <code>x_dev</code>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/host_vector.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  <span class="type">float</span> a = <span class="number">3.14f</span>;</span><br><span class="line">  <span class="function">thrust::host_vector&lt;<span class="type">float</span>&gt; <span class="title">x_host</span><span class="params">(n)</span></span>;</span><br><span class="line">  <span class="function">thrust::host_vector&lt;<span class="type">float</span>&gt; <span class="title">y_host</span><span class="params">(n)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    x_host[i] = std::<span class="built_in">rand</span>() * (<span class="number">1.f</span> / RAND_MAX);</span><br><span class="line">    y_host[i] = std::<span class="built_in">rand</span>() * (<span class="number">1.f</span> / RAND_MAX);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  thrust::device_vector&lt;<span class="type">float</span>&gt; x_dev = x_host;</span><br><span class="line">  thrust::device_vector&lt;<span class="type">float</span>&gt; y_dev = x_host;</span><br><span class="line"></span><br><span class="line">  parallel_for&lt;&lt;&lt;n / <span class="number">512</span>, <span class="number">128</span>&gt;&gt;&gt;(</span><br><span class="line">      n, [a, x_dev = x_dev.<span class="built_in">data</span>(), y_dev = y_dev.<span class="built_in">data</span>()] __device__(<span class="type">int</span> i) &#123;</span><br><span class="line">        x_dev[i] = a * x_dev[i] + y_dev[i];</span><br><span class="line">      &#125;);</span><br><span class="line"></span><br><span class="line">  x_host = x_dev;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;x[%d] = %f\n&quot;</span>, i, x_host[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="使用-Thrust-模板函数：thrust-generate"><a href="#使用-Thrust-模板函数：thrust-generate" class="headerlink" title="使用 Thrust 模板函数：thrust::generate"></a>使用 Thrust 模板函数：thrust::generate</h3><p>Thrust 提供了与 C++ 标准库类似的模板函数，例如 <code>thrust::generate(b, e, f)</code>，它的作用与 <code>std::generate</code> 相似，能够批量生成数据并填充到区间 <code>[b, e)</code> 中。第三个参数是一个函数，这里我们使用了一个 lambda 表达式。</p>
<p>前两个迭代器参数分别是 <code>device_vector</code> 或 <code>host_vector</code> 的开始和结束迭代器，可以通过成员函数 <code>begin()</code> 和 <code>end()</code> 获取。第三个参数可以是任意函数，这里用了 lambda 表达式。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/generate.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/host_vector.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  <span class="type">float</span> a = <span class="number">3.14f</span>;</span><br><span class="line">  <span class="function">thrust::host_vector&lt;<span class="type">float</span>&gt; <span class="title">x_host</span><span class="params">(n)</span></span>;</span><br><span class="line">  <span class="function">thrust::host_vector&lt;<span class="type">float</span>&gt; <span class="title">y_host</span><span class="params">(n)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> float_rand = [] &#123; <span class="keyword">return</span> std::<span class="built_in">rand</span>() * (<span class="number">1.f</span> / RAND_MAX); &#125;;</span><br><span class="line">  thrust::<span class="built_in">generate</span>(x_host.<span class="built_in">begin</span>(), x_host.<span class="built_in">end</span>(), float_rand);</span><br><span class="line">  thrust::<span class="built_in">generate</span>(y_host.<span class="built_in">begin</span>(), y_host.<span class="built_in">end</span>(), float_rand);</span><br><span class="line"></span><br><span class="line">  thrust::device_vector&lt;<span class="type">float</span>&gt; x_dev = x_host;</span><br><span class="line">  thrust::device_vector&lt;<span class="type">float</span>&gt; y_dev = x_host;</span><br><span class="line"></span><br><span class="line">  parallel_for&lt;&lt;&lt;n / <span class="number">512</span>, <span class="number">128</span>&gt;&gt;&gt;(</span><br><span class="line">      n, [a, x_dev = x_dev.<span class="built_in">data</span>(), y_dev = y_dev.<span class="built_in">data</span>()] __device__(<span class="type">int</span> i) &#123;</span><br><span class="line">        x_dev[i] = a * x_dev[i] + y_dev[i];</span><br><span class="line">      &#125;);</span><br><span class="line"></span><br><span class="line">  x_host = x_dev;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;x[%d] = %f\n&quot;</span>, i, x_host[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="使用-Thrust-模板函数：thrust-for-each"><a href="#使用-Thrust-模板函数：thrust-for-each" class="headerlink" title="使用 Thrust 模板函数：thrust::for_each"></a>使用 Thrust 模板函数：thrust::for_each</h3><p>同理，<code>thrust::for_each(b, e, f)</code> 对标 C++ 的 <code>std::for_each</code>，用于对区间 <code>[b, e)</code> 中的每个元素 <code>x</code> 调用函数 <code>f(x)</code>。其中，<code>x</code> 实际上是一个引用。如果使用常量迭代器，则是常引用，可以通过 <code>cbegin()</code> 和 <code>cend()</code> 获取常值迭代器。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/for_each.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/generate.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/host_vector.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  <span class="type">float</span> a = <span class="number">3.14f</span>;</span><br><span class="line">  <span class="function">thrust::host_vector&lt;<span class="type">float</span>&gt; <span class="title">x_host</span><span class="params">(n)</span></span>;</span><br><span class="line">  <span class="function">thrust::host_vector&lt;<span class="type">float</span>&gt; <span class="title">y_host</span><span class="params">(n)</span></span>;</span><br><span class="line"></span><br><span class="line">  thrust::for_each(x_host.<span class="built_in">begin</span>(), x_host.<span class="built_in">end</span>(),</span><br><span class="line">                   [](<span class="type">float</span> &amp;x) &#123; x = std::<span class="built_in">rand</span>() * (<span class="number">1.f</span> / RAND_MAX); &#125;);</span><br><span class="line">  thrust::for_each(y_host.<span class="built_in">begin</span>(), y_host.<span class="built_in">end</span>(),</span><br><span class="line">                   [](<span class="type">float</span> &amp;y) &#123; y = std::<span class="built_in">rand</span>() * (<span class="number">1.f</span> / RAND_MAX); &#125;);</span><br><span class="line"></span><br><span class="line">  thrust::device_vector&lt;<span class="type">float</span>&gt; x_dev = x_host;</span><br><span class="line">  thrust::device_vector&lt;<span class="type">float</span>&gt; y_dev = x_host;</span><br><span class="line"></span><br><span class="line">  thrust::for_each(x_dev.<span class="built_in">begin</span>(), x_dev.<span class="built_in">end</span>(),</span><br><span class="line">                   [] __device__(<span class="type">float</span> &amp;x) &#123; x += <span class="number">100.f</span>; &#125;);</span><br><span class="line"></span><br><span class="line">  thrust::for_each(x_dev.<span class="built_in">cbegin</span>(), x_dev.<span class="built_in">cend</span>(),</span><br><span class="line">                   [] __device__(<span class="type">float</span> <span class="type">const</span> &amp;x) &#123; <span class="built_in">printf</span>(<span class="string">&quot;%f\n&quot;</span>, x); &#125;);</span><br><span class="line"></span><br><span class="line">  parallel_for&lt;&lt;&lt;n / <span class="number">512</span>, <span class="number">128</span>&gt;&gt;&gt;(</span><br><span class="line">      n, [a, x_dev = x_dev.<span class="built_in">data</span>(), y_dev = y_dev.<span class="built_in">data</span>()] __device__(<span class="type">int</span> i) &#123;</span><br><span class="line">        x_dev[i] = a * x_dev[i] + y_dev[i];</span><br><span class="line">      &#125;);</span><br><span class="line"></span><br><span class="line">  x_host = x_dev;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;x[%d] = %f\n&quot;</span>, i, x_host[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>当然还有 thrust::reduce，thrust::sort，thrust::find_if，thrust::count_if，thrust::reverse，thrust::inclusive_scan 等。</li>
</ul>
<h3 id="Thrust-模板函数的特点：自动决定-CPU-或-GPU-执行"><a href="#Thrust-模板函数的特点：自动决定-CPU-或-GPU-执行" class="headerlink" title="Thrust 模板函数的特点：自动决定 CPU 或 GPU 执行"></a>Thrust 模板函数的特点：自动决定 CPU 或 GPU 执行</h3><p>Thrust 的 <code>for_each</code> 可以作用于 <code>device_vector</code> 也可以作用于 <code>host_vector</code>。当作用于 <code>host_vector</code> 时，函数会在 CPU 上执行，而作用于 <code>device_vector</code> 时，则会在 GPU 上执行。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/Clip_2024-11-07_23-40-44.png" class="" title="Clip_2024-11-07_23-40-44">

<p>例如，针对 <code>x_host</code> 使用 <code>for_each</code> 时，lambda 表达式不需要修饰，而针对 <code>x_dev</code> 使用时，lambda 表达式需要加上 <code>__device__</code> 修饰符。</p>
<h3 id="使用-counting-iterator-实现整数区间循环"><a href="#使用-counting-iterator-实现整数区间循环" class="headerlink" title="使用 counting_iterator 实现整数区间循环"></a>使用 counting_iterator 实现整数区间循环</h3><p>Thrust 中的迭代器区间操作（如 <code>thrust::for_each</code>、<code>thrust::transform</code>、<code>thrust::reduce</code> 等）通常基于迭代器区间。<code>counting_iterator</code> 是一种特殊的迭代器，能够生成递增的整数序列，适合用于这种情况。</p>
<p>这是 Thrust 提供的一种特殊的迭代器，当需要在 Thrust 算法中使用一个递增整数序列时，<code>counting_iterator</code> 就可以作为迭代器传递</p>
<ul>
<li><code>counting_iterator</code> 实际上是一个生成器，它的作用是 <strong>生成一个递增的数值序列</strong></li>
</ul>
<p>用 <code>thrust::make_counting_iterator(num)</code> 构建一个计数迭代器，他作为区间表示的就是整数的区间。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/for_each.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/generate.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/host_vector.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  thrust::for_each(thrust::<span class="built_in">make_counting_iterator</span>(<span class="number">0</span>),</span><br><span class="line">                   thrust::<span class="built_in">make_counting_iterator</span>(<span class="number">10</span>),</span><br><span class="line">                   [] __device__(<span class="type">int</span> i) &#123; <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, i); &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//  0</span></span><br><span class="line"><span class="comment">//  1</span></span><br><span class="line"><span class="comment">//  2</span></span><br><span class="line"><span class="comment">//  3</span></span><br><span class="line"><span class="comment">//  4</span></span><br><span class="line"><span class="comment">//  5</span></span><br><span class="line"><span class="comment">//  6</span></span><br><span class="line"><span class="comment">//  7</span></span><br><span class="line"><span class="comment">//  8</span></span><br><span class="line"><span class="comment">//  9</span></span><br></pre></td></tr></table></figure>

<h3 id="使用-zip-iterator-合并多个迭代器"><a href="#使用-zip-iterator-合并多个迭代器" class="headerlink" title="使用 zip_iterator 合并多个迭代器"></a>使用 zip_iterator 合并多个迭代器</h3><p><code>zip_iterator</code> 可以看作是一个复合迭代器，它将多个容器（或迭代器）作为输入，生成一个新的迭代器，这个新的迭代器能够同时访问所有输入容器中对应位置的元素。在每次迭代时，<code>zip_iterator</code> 会返回多个容器中相应位置的元素。</p>
<p>可以通过 <code>thrust::make_zip_iterator(a, b)</code> 将多个迭代器合并，就像 Python 中的 <code>zip</code> 函数一样。</p>
<p>在使用时，可以通过 <code>auto const &amp;tup</code> 来捕获每次迭代返回的元组，并使用 <code>thrust::get&lt;index&gt;(tup)</code> 获取其中第 <code>index</code> 个元素。之所以这么处理，是因为 Thrust 需要兼容一些使用较老标准（如 C++03）的程序，尽管现在可以更简洁地使用 C++11 的 <code>std::tuple</code> 和 C++17 的结构绑定语法。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/for_each.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/generate.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/host_vector.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Func</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_for</span><span class="params">(<span class="type">int</span> n, Func func)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  <span class="type">float</span> a = <span class="number">3.14f</span>;</span><br><span class="line">  <span class="function">thrust::host_vector&lt;<span class="type">float</span>&gt; <span class="title">x_host</span><span class="params">(n)</span></span>;</span><br><span class="line">  <span class="function">thrust::host_vector&lt;<span class="type">float</span>&gt; <span class="title">y_host</span><span class="params">(n)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> float_rand = [] &#123; <span class="keyword">return</span> std::<span class="built_in">rand</span>() * (<span class="number">1.f</span> / RAND_MAX); &#125;;</span><br><span class="line">  thrust::<span class="built_in">generate</span>(x_host.<span class="built_in">begin</span>(), x_host.<span class="built_in">end</span>(), float_rand);</span><br><span class="line">  thrust::<span class="built_in">generate</span>(y_host.<span class="built_in">begin</span>(), y_host.<span class="built_in">end</span>(), float_rand);</span><br><span class="line"></span><br><span class="line">  thrust::device_vector&lt;<span class="type">float</span>&gt; x_dev = x_host;</span><br><span class="line">  thrust::device_vector&lt;<span class="type">float</span>&gt; y_dev = x_host;</span><br><span class="line"></span><br><span class="line">  thrust::for_each(thrust::<span class="built_in">make_zip_iterator</span>(x_dev.<span class="built_in">begin</span>(), y_dev.<span class="built_in">cbegin</span>()),</span><br><span class="line">                   thrust::<span class="built_in">make_zip_iterator</span>(x_dev.<span class="built_in">end</span>(), y_dev.<span class="built_in">cend</span>()),</span><br><span class="line">                   [a] __device__(<span class="keyword">auto</span> <span class="type">const</span> &amp;tup) &#123;</span><br><span class="line">                     <span class="keyword">auto</span> &amp;x = thrust::<span class="built_in">get</span>&lt;<span class="number">0</span>&gt;(tup);</span><br><span class="line">                     <span class="keyword">auto</span> <span class="type">const</span> &amp;y = thrust::<span class="built_in">get</span>&lt;<span class="number">1</span>&gt;(tup);</span><br><span class="line">                     x = a * x + y;</span><br><span class="line">                   &#125;);</span><br><span class="line"></span><br><span class="line">  x_host = x_dev;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;x[%d] = %f\n&quot;</span>, i, x_host[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样，我们能够通过 <code>zip_iterator</code> 同时操作多个容器。</p>
<h2 id="第七章：原子操作"><a href="#第七章：原子操作" class="headerlink" title="第七章：原子操作"></a>第七章：原子操作</h2><h3 id="经典案例：数组求和"><a href="#经典案例：数组求和" class="headerlink" title="经典案例：数组求和"></a>经典案例：数组求和</h3><p>如何并行地对数组进行求和操作？</p>
<p>首先让我们试着用串行的思路来解题。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CudaAllocator.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;ticktock.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_sum</span><span class="params">(<span class="type">int</span> *sum, <span class="type">int</span> <span class="type">const</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    sum[<span class="number">0</span>] += arr[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">sum</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    arr[i] = std::<span class="built_in">rand</span>() % <span class="number">4</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">TICK</span>(parallel_sum);</span><br><span class="line">  parallel_sum&lt;&lt;&lt;n / <span class="number">128</span>, <span class="number">128</span>&gt;&gt;&gt;(sum.<span class="built_in">data</span>(), arr.<span class="built_in">data</span>(),</span><br><span class="line">                                 n);  <span class="comment">// 对数组arr求和，结果保存在sum[0]</span></span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">TOCK</span>(parallel_sum);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;result: %d\n&quot;</span>, sum[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// parallel_sum: 0.931437s</span></span><br><span class="line"><span class="comment">// result: 3</span></span><br></pre></td></tr></table></figure>

<p>因为 <strong>global</strong> 函数不能返回值，只能通过指针。因此我们先分配一个大小为 1 的 sum 数组，用来存储数组元素的和。这样我们同步之后就可以通过 sum[0] 看到求和的结果了。</p>
<p>可是算出来的结果却明显不对，为什么？</p>
<p>在并行计算中，<code>sum[0] += arr[i]</code> 被拆解成了以下四步操作：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum[<span class="number">0</span>] += arr[i];</span><br></pre></td></tr></table></figure>

<ul>
<li>读取 <code>sum[0]</code> 到寄存器 A</li>
<li>读取 <code>arr[i]</code> 到寄存器 B</li>
<li>将寄存器 A 和寄存器 B 的值相加</li>
<li>写回寄存器 A 到 <code>sum[0]</code></li>
</ul>
<p>问题在于，如果两个线程同时访问 <code>sum[0]</code>，会出现竞争条件。例如：</p>
<ul>
<li>线程 0：读取 <code>sum[0]</code> 到寄存器 A（A &#x3D; 0）</li>
<li>线程 1：读取 <code>sum[0]</code> 到寄存器 A（A &#x3D; 0）</li>
<li>线程 0：读取 <code>arr[0]</code> 到寄存器 B（B &#x3D; arr[0]）</li>
<li>线程 1：读取 <code>arr[1]</code> 到寄存器 B（B &#x3D; arr[1]）</li>
<li>线程 0：将寄存器 A 加上寄存器 B（A &#x3D; arr[0]）</li>
<li>线程 1：将寄存器 A 加上寄存器 B（A &#x3D; arr[1]）</li>
<li>线程 0：将寄存器 A 写回到 <code>sum[0]</code>（<code>sum[0] = arr[0]</code>）</li>
<li>线程 1：将寄存器 A 写回到 <code>sum[0]</code>（<code>sum[0] = arr[1]</code>）</li>
</ul>
<p>最终，<code>sum[0]</code> 的值会变成 <code>arr[1]</code>，而不是期望的 <code>arr[0] + arr[1]</code>。这样就导致了错误的结果。</p>
<h3 id="解决方案：使用原子操作"><a href="#解决方案：使用原子操作" class="headerlink" title="解决方案：使用原子操作"></a>解决方案：使用原子操作</h3><p>所以，熟悉 CPU 上并行编程的同学们可能就明白了，要用 atomic 对吧！</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CudaAllocator.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;ticktock.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_sum</span><span class="params">(<span class="type">int</span> *sum, <span class="type">int</span> <span class="type">const</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="built_in">atomicAdd</span>(&amp;sum[<span class="number">0</span>], arr[i]);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">sum</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    arr[i] = std::<span class="built_in">rand</span>() % <span class="number">4</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">TICK</span>(parallel_sum);</span><br><span class="line">  parallel_sum&lt;&lt;&lt;n / <span class="number">128</span>, <span class="number">128</span>&gt;&gt;&gt;(sum.<span class="built_in">data</span>(), arr.<span class="built_in">data</span>(), n);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">TOCK</span>(parallel_sum);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;result: %d\n&quot;</span>, sum[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// parallel_sum: 0.383628s</span></span><br><span class="line"><span class="comment">// result: 98229</span></span><br></pre></td></tr></table></figure>

<p>原子操作的功能就是保证读取&#x2F;加法&#x2F;写回三个操作，不会有另一个线程来打扰。</p>
<p>CUDA 也提供了这种函数，即 atomicAdd。效果和 +&#x3D; 一样，不过是原子的。他的第一个参数是个指针，指向要修改的地址。第二个参数是要增加多少。也就是说：</p>
<p><code>atomicAdd(dst, src)</code> 和 <code>*dst += src</code> 作用相同，只不过前者是原子操作，能够避免竞争。</p>
<h3 id="atomicAdd：会返回旧值（划重点！）"><a href="#atomicAdd：会返回旧值（划重点！）" class="headerlink" title="atomicAdd：会返回旧值（划重点！）"></a>atomicAdd：会返回旧值（划重点！）</h3><p><code>atomicAdd</code> 会返回旧值——依靠这个特性可以实现一些很有意思的操作</p>
<ul>
<li>一个常见的需求是在并行计算中向一个数组中追加元素。如何在多个线程并行执行时确保每个线程都能够正确地将元素追加到数组的末尾而不会发生冲突呢？</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CudaAllocator.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;ticktock.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_filter</span><span class="params">(<span class="type">int</span> *sum, <span class="type">int</span> *res, <span class="type">int</span> <span class="type">const</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="keyword">if</span> (arr[i] &gt;= <span class="number">2</span>) &#123;	<span class="comment">// 手动实现一个过滤器功能</span></span><br><span class="line">      <span class="type">int</span> loc = <span class="built_in">atomicAdd</span>(&amp;sum[<span class="number">0</span>], <span class="number">1</span>);</span><br><span class="line">      res[loc] = arr[i];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">1</span> &lt;&lt; <span class="number">24</span>;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">sum</span>(<span class="number">1</span>);</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">res</span>(n);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    arr[i] = std::<span class="built_in">rand</span>() % <span class="number">4</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">TICK</span>(parallel_filter);</span><br><span class="line">  parallel_filter&lt;&lt;&lt;n / <span class="number">4096</span>, <span class="number">512</span>&gt;&gt;&gt;(sum.<span class="built_in">data</span>(), res.<span class="built_in">data</span>(), arr.<span class="built_in">data</span>(), n);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">TOCK</span>(parallel_filter);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; sum[<span class="number">0</span>]; i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (res[i] &lt; <span class="number">2</span>) &#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">&quot;Wrong At %d\n&quot;</span>, i);</span><br><span class="line">      <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;All Correct!\n&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// parallel_filter: 0.848773s</span></span><br><span class="line"><span class="comment">// All Correct!</span></span><br></pre></td></tr></table></figure>

<p>我们有一个全局数组 <code>res</code> 和一个用于记录数组当前大小的变量 <code>sum</code>，我们希望利用 <code>atomicAdd</code> 实现类似 <code>push_back</code> 的操作：</p>
<ol>
<li>每当线程需要将数据插入到 <code>res</code> 中时，它首先调用 <code>atomicAdd</code> 来获取当前数组的大小，并同时将数组的大小加 1。</li>
<li>然后，线程根据 <code>atomicAdd</code> 返回的旧值将数据写入到 <code>res[old]</code> 位置，确保每个线程都能在一个唯一的位置上写入数据。</li>
</ol>
<p>这种方法通过 <code>atomicAdd</code> 原子地更新 <code>sum</code>，保证了不同线程不会争抢同一个位置，从而避免了数据竞争。</p>
<p><code>old = atomicAdd(dst, src)</code> 其实相当于：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">old = *dst;</span><br><span class="line">*dst += src;</span><br></pre></td></tr></table></figure>

<p>利用这一点可以实现往一个全局的数组 res 里追加数据的效果（push_back），其中 sum 起到了记录当前数组大小的作用。</p>
<h3 id="其它原子操作"><a href="#其它原子操作" class="headerlink" title="其它原子操作"></a>其它原子操作</h3><table>
<thead>
<tr>
<th>原子操作</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>atomicAdd(dst, src)</code></td>
<td><code>*dst += src</code></td>
</tr>
<tr>
<td><code>atomicSub(dst, src)</code></td>
<td><code>*dst -= src</code></td>
</tr>
<tr>
<td><code>atomicOr(dst, src)</code></td>
<td>&#96;*dst</td>
</tr>
<tr>
<td><code>atomicAnd(dst, src)</code></td>
<td><code>*dst &amp;= src</code></td>
</tr>
<tr>
<td><code>atomicXor(dst, src)</code></td>
<td><code>*dst ^= src</code></td>
</tr>
<tr>
<td><code>atomicMax(dst, src)</code></td>
<td><code>*dst = std::max(*dst, src)</code></td>
</tr>
<tr>
<td><code>atomicMin(dst, src)</code></td>
<td><code>*dst = std::min(*dst, src)</code></td>
</tr>
</tbody></table>
<p>当然，他们也都会返回旧值（如果需要的话）。</p>
<h3 id="atomicExch：原子交换操作，返回旧值"><a href="#atomicExch：原子交换操作，返回旧值" class="headerlink" title="atomicExch：原子交换操作，返回旧值"></a>atomicExch：原子交换操作，返回旧值</h3><p>除了带有运算的原子操作，<code>atomicExch</code> 是一种仅进行写入操作而不进行读取的原子操作。</p>
<p><code>old = atomicExch(dst, src)</code> 等同于：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">old = *dst;</span><br><span class="line">*dst = src;</span><br></pre></td></tr></table></figure>

<p>说明：<code>Exch</code> 是 <code>exchange</code> 的缩写，对应于 <code>std::atomic</code> 中的 <code>exchange</code> 函数。</p>
<h3 id="atomicCAS：原子比较与交换的妙用"><a href="#atomicCAS：原子比较与交换的妙用" class="headerlink" title="atomicCAS：原子比较与交换的妙用"></a>atomicCAS：原子比较与交换的妙用</h3><h4 id="原子判断是否相等，相等则写入并返回旧值"><a href="#原子判断是否相等，相等则写入并返回旧值" class="headerlink" title="原子判断是否相等，相等则写入并返回旧值"></a>原子判断是否相等，相等则写入并返回旧值</h4><p><code>old = atomicCAS(dst, cmp, src)</code> 实现的操作类似于：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">old = *dst;</span><br><span class="line"><span class="keyword">if</span> (old == cmp)</span><br><span class="line">    *dst = src;</span><br></pre></td></tr></table></figure>

<p>为什么需要这种复杂的原子指令？</p>
<h4 id="实现自定义原子操作"><a href="#实现自定义原子操作" class="headerlink" title="实现自定义原子操作"></a>实现自定义原子操作</h4><p><code>atomicCAS</code> 的强大之处在于它能实现 CUDA 未直接提供的任意原子读-修改-写操作。比如，使用 <code>atomicCAS</code> 可以模拟整数的原子加法，效果与 <code>atomicAdd</code> 相同：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CudaAllocator.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;ticktock.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__device__ __inline__ <span class="type">int</span> <span class="title">my_atomic_add</span><span class="params">(<span class="type">int</span> *dst, <span class="type">int</span> src)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> old = *dst, expect;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    expect = old;</span><br><span class="line">    old = <span class="built_in">atomicCAS</span>(dst, expect, expect + src);  <span class="comment">// 使用 atomicCAS 实现原子加法</span></span><br><span class="line">  &#125; <span class="keyword">while</span> (expect != old);</span><br><span class="line">  <span class="keyword">return</span> old;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_sum</span><span class="params">(<span class="type">int</span> *sum, <span class="type">int</span> <span class="type">const</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> local_sum = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n; </span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    local_sum += arr[i];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">my_atomic_add</span>(&amp;sum[<span class="number">0</span>], local_sum);  <span class="comment">// 调用自定义的原子加法</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">65536</span>;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">sum</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    arr[i] = std::<span class="built_in">rand</span>() % <span class="number">4</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">TICK</span>(parallel_sum);</span><br><span class="line">  parallel_sum&lt;&lt;&lt;n / <span class="number">4096</span>, <span class="number">512</span>&gt;&gt;&gt;(sum.<span class="built_in">data</span>(), arr.<span class="built_in">data</span>(), n);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">TOCK</span>(parallel_sum);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;result: %d\n&quot;</span>, sum[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// parallel_sum: 8.323379s</span></span><br><span class="line"><span class="comment">// result: 98229</span></span><br></pre></td></tr></table></figure>

<p>此外，如果将 <code>expect + src</code> 替换为 <code>expect * src</code>，就能实现原子乘法（<code>atomicMul</code>），尽管 CUDA 原生并不提供这个功能，我们仍然可以通过 <code>atomicCAS</code> 来实现：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__device__ __inline__ <span class="type">int</span> <span class="title">my_atomic_add</span><span class="params">(<span class="type">int</span> *dst, <span class="type">int</span> src)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> old = *dst, expect;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    expect = old;</span><br><span class="line">    old = <span class="built_in">atomicCAS</span>(dst, expect, expect * src);  <span class="comment">// 使用 atomicCAS 实现原子乘法</span></span><br><span class="line">  &#125; <span class="keyword">while</span> (expect != old);</span><br><span class="line">  <span class="keyword">return</span> old;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>值得一提的是，在某些较老版本的 CUDA 中，<code>atomicAdd</code> 不支持 <code>float</code> 类型。此时可以通过 <code>atomicCAS</code> 配合按位转换函数（<code>__float_as_int</code> 和 <code>__int_as_float</code>）来实现浮点数的原子加法：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__device__ __inline__ <span class="type">int</span> <span class="title">float_atomic_add</span><span class="params">(<span class="type">float</span> *dst, <span class="type">float</span> src)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> old = __float_as_int(*dst), expect;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    expect = old;</span><br><span class="line">    old = <span class="built_in">atomicCAS</span>((<span class="type">int</span> *)dst, expect,</span><br><span class="line">                    __float_as_int(__int_as_float(expect) + src));  <span class="comment">// 原子浮点加法</span></span><br><span class="line">  &#125; <span class="keyword">while</span> (expect != old);</span><br><span class="line">  <span class="keyword">return</span> old;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当然，CUDA 11 已原生支持 <code>atomicAdd</code> 对 <code>float</code> 类型的支持，此处仅作为展示 <code>atomicCAS</code> 灵活性的案例。</p>
<p><strong>注意：atomicCAS非常非常影响性能，如果CUDA提供了相应的操作，就不要使用atomicCAS去模拟！！！</strong></p>
<h3 id="原子操作的性能影响"><a href="#原子操作的性能影响" class="headerlink" title="原子操作的性能影响"></a>原子操作的性能影响</h3><p>原子操作的主要问题在于它们需要保证同一时刻只有一个线程可以修改某个内存地址。当多个线程尝试同时修改同一个地址时，操作会像“排队”一样，一个线程修改完后另一个线程才能进行，导致性能显著下降。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CudaAllocator.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;ticktock.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_filter</span><span class="params">(<span class="type">int</span> *sum, <span class="type">int</span> *res, <span class="type">int</span> <span class="type">const</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    <span class="keyword">if</span> (arr[i] &gt;= <span class="number">2</span>) &#123;</span><br><span class="line">      <span class="type">int</span> loc = <span class="built_in">atomicAdd</span>(&amp;sum[<span class="number">0</span>], <span class="number">1</span>);  <span class="comment">// 使用原子加法</span></span><br><span class="line">      res[loc] = arr[i];  <span class="comment">// 将符合条件的元素写入结果数组</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">1</span> &lt;&lt; <span class="number">24</span>;  <span class="comment">// 2^24个元素</span></span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">sum</span>(<span class="number">1</span>);</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">res</span>(n);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    arr[i] = std::<span class="built_in">rand</span>() % <span class="number">4</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">TICK</span>(parallel_filter);</span><br><span class="line">  parallel_filter&lt;&lt;&lt;n / <span class="number">4096</span>, <span class="number">512</span>&gt;&gt;&gt;(sum.<span class="built_in">data</span>(), res.<span class="built_in">data</span>(), arr.<span class="built_in">data</span>(), n);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">TOCK</span>(parallel_filter);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; sum[<span class="number">0</span>]; i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (res[i] &lt; <span class="number">2</span>) &#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">&quot;Wrong At %d\n&quot;</span>, i);</span><br><span class="line">      <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;All Correct!\n&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// parallel_filter: 0.318569s</span></span><br><span class="line"><span class="comment">// All Correct!</span></span><br></pre></td></tr></table></figure>

<h4 id="性能意外地很快？"><a href="#性能意外地很快？" class="headerlink" title="性能意外地很快？"></a>性能意外地很快？</h4><p>尽管数据量达到 <code>2^24</code> 个元素，理论上使用原子操作会导致性能瓶颈，但这里的代码运行速度仍然很快，几乎没有明显的性能下降。</p>
<p><strong>原因：</strong> 这是因为 CUDA 编译器进行了智能优化。它通过某些技术（如线程间的内存访问优化、局部内存的使用等）减少了原子操作的竞争，从而提高了整体性能。</p>
<p>稍后我们会深入探讨 CUDA 如何通过这些优化来提升原子操作性能。</p>
<h3 id="解决方案：线程局部变量（TLS）"><a href="#解决方案：线程局部变量（TLS）" class="headerlink" title="解决方案：线程局部变量（TLS）"></a>解决方案：线程局部变量（TLS）</h3><p>为了解决原子操作导致的性能瓶颈，一种常见的优化方法是：每个线程先将计算结果累加到一个局部变量 <code>local_sum</code> 中，然后在每个线程的工作完成后，再一次性将局部变量的值通过原子操作加到全局变量 <code>sum</code> 中。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;CudaAllocator.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helper_cuda.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;ticktock.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">parallel_sum</span><span class="params">(<span class="type">int</span> *sum, <span class="type">int</span> <span class="type">const</span> *arr, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> local_sum = <span class="number">0</span>;  <span class="comment">// 每个线程的局部变量</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n;</span><br><span class="line">       i += blockDim.x * gridDim.x) &#123;</span><br><span class="line">    local_sum += arr[i];  <span class="comment">// 将结果累加到局部变量</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">atomicAdd</span>(&amp;sum[<span class="number">0</span>], local_sum);  <span class="comment">// 一次性将局部和全局相加</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> n = <span class="number">1</span> &lt;&lt; <span class="number">24</span>;  <span class="comment">// 2^24个元素</span></span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">arr</span>(n);</span><br><span class="line">  std::vector&lt;<span class="type">int</span>, CudaAllocator&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">sum</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    arr[i] = std::<span class="built_in">rand</span>() % <span class="number">4</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">TICK</span>(parallel_sum);</span><br><span class="line">  parallel_sum&lt;&lt;&lt;n / <span class="number">4096</span>, <span class="number">512</span>&gt;&gt;&gt;(sum.<span class="built_in">data</span>(), arr.<span class="built_in">data</span>(), n);</span><br><span class="line">  <span class="built_in">checkCudaErrors</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">TOCK</span>(parallel_sum);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;result: %d\n&quot;</span>, sum[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// parallel_sum: 0.392188s</span></span><br><span class="line"><span class="comment">// result: 25172683</span></span><br></pre></td></tr></table></figure>

<h4 id="优化效果"><a href="#优化效果" class="headerlink" title="优化效果"></a>优化效果</h4><p>这样每个线程仅需要进行一次原子操作，而不像原来那样在每次累加时都进行原子操作，从而大大减少了原子操作的开销。</p>
<p>此外，为了进一步减少原子操作的次数，建议调小 <code>gridDim</code> 和 <code>blockDim</code>，使其小于数据量 <code>n</code>，这样局部变量才有足够的累积次数。例如，上面的代码将 <code>gridDim * blockDim</code> 减小了 8 倍，从而减少了原子操作的次数。</p>
<p>这就是 <strong>TLS</strong>（Thread Local Storage，线程本地存储）的基本原理：每个线程使用局部变量来暂存结果，最后才将结果进行汇总。通过这种方式，可以有效减少对全局内存的竞争和原子操作的频繁调用。</p>
<h2 id="第8章：板块与共享内存"><a href="#第8章：板块与共享内存" class="headerlink" title="第8章：板块与共享内存"></a>第8章：板块与共享内存</h2><h3 id="为什么需要区分出板块的概念？"><a href="#为什么需要区分出板块的概念？" class="headerlink" title="为什么需要区分出板块的概念？"></a>为什么需要区分出板块的概念？</h3><p>之前说到实际的线程数量就是板块数量(gridDim)乘以每板块线程数量(blockDim)。</p>
<p>那么为什么中间要插一个板块呢？感觉很不直观，不如直接说线程数量不就好了？</p>
<p>这还得从 GPU 的硬件架构说起。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/image-20241116001039500.png" class="" title="image-20241116001039500">

<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/2024-11-16_01-10-23.png" class="" title="2024-11-16_01-10-23">

<h3 id="SM（Streaming-Multiprocessors）与板块（block）"><a href="#SM（Streaming-Multiprocessors）与板块（block）" class="headerlink" title="SM（Streaming Multiprocessors）与板块（block）"></a>SM（Streaming Multiprocessors）与板块（block）</h3><p>GPU 是由多个流式多处理器（SM）组成的。每个 SM 可以处理一个或多个板块。</p>
<p>SM 又由多个流式单处理器（SP）组成。每个 SP 可以处理一个或多个线程。</p>
<p>每个 SM 都有自己的一块共享内存（shared memory），他的性质类似于 CPU 中的缓存——和主存相比很小，但是很快，用于缓冲临时数据。还有点特殊的性质，我们稍后会讲。</p>
<p>通常板块数量总是大于 SM 的数量，这时英伟达驱动就会在多个 SM 之间调度你提交的各个板块。正如操作系统在多个 CPU 核心之间调度线程那样……</p>
<p>不过有一点不同，GPU 不会像 CPU 那样做时间片轮换——板块一旦被调度到了一个 SM 上，就会一直执行，直到他执行完退出，这样的好处是不存在保存和切换上下文（寄存器，共享内存等）的开销，毕竟 GPU 的数据量比较大，禁不起这样切换来切换去……</p>
<p>一个 SM 可同时运行多个板块，这时多个板块共用同一块共享内存（每块分到的就少了）。</p>
<p>而板块内部的每个线程，则是被进一步调度到 SM 上的每个 SP。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://ming-z0.github.io">Ming</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ming-z0.github.io/2024/10/24/CUDA/CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B/">https://ming-z0.github.io/2024/10/24/CUDA/CUDA开始的GPU编程/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://ming-z0.github.io" target="_blank">MINGの部落格</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/CUDA/">CUDA</a><a class="post-meta__tags" href="/tags/GPU%E7%BC%96%E7%A8%8B/">GPU编程</a></div><div class="post_share"><div class="social-share" data-image="/./img/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2/6.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/%E6%89%93%E8%B5%8F/wechat.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/%E6%89%93%E8%B5%8F/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/10/23/C++/%E6%A0%87%E5%87%86%E5%BA%93/%E4%B8%89%E3%80%81set%E7%B3%BB%E5%88%97%E5%AE%B9%E5%99%A8%E4%B8%8E%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%88%86%E7%B1%BB/" title="全面理解STL-set系列容器与迭代器分类"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./img/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2/4.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">全面理解STL-set系列容器与迭代器分类</div></div></a></div><div class="next-post pull-right"><a href="/2024/10/29/CUDA/%E6%80%A5%E9%80%9F%E6%90%AD%E5%BB%BACUDA%E4%BD%93%E9%AA%8C%E7%8E%AF%E5%A2%83/" title="WSL2快速搭建CUDA体验环境"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./img/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2/3.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">WSL2快速搭建CUDA体验环境</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/10/29/CUDA/%E6%80%A5%E9%80%9F%E6%90%AD%E5%BB%BACUDA%E4%BD%93%E9%AA%8C%E7%8E%AF%E5%A2%83/" title="WSL2快速搭建CUDA体验环境"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./img/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2/3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2024-11-09</div><div class="title">WSL2快速搭建CUDA体验环境</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Twikoo</span><span class="switch-btn"></span><span class="second-comment">Livere</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div id="lv-container" data-id="city" data-uid="MTAyMC82MDIzOS8zNjcwNw"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./img/%E5%A4%B4%E5%83%8F.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Ming</div><div class="author-info__description">一个记录、分享自己学习过程的博客</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ming-z0"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ming-z0" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:ming-zhanglu@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#CUDA%E5%BC%80%E5%A7%8B%E7%9A%84GPU%E7%BC%96%E7%A8%8B"><span class="toc-text">CUDA开始的GPU编程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC0%E7%AB%A0%EF%BC%9AHello-world-from-GPU"><span class="toc-text">第0章：Hello, world from GPU!</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CMake%E4%B8%AD%E5%90%AF%E7%94%A8CUDA%E6%94%AF%E6%8C%81"><span class="toc-text">CMake中启用CUDA支持</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CUDA%E7%BC%96%E8%AF%91%E5%99%A8%E5%85%BC%E5%AE%B9C-17"><span class="toc-text">CUDA编译器兼容C++17</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E4%B8%80%E6%AE%B5%E5%9C%A8GPU%E4%B8%8A%E8%BF%90%E8%A1%8C%E7%9A%84%E4%BB%A3%E7%A0%81"><span class="toc-text">编写一段在GPU上运行的代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E6%B2%A1%E5%8F%8D%E5%BA%94%EF%BC%9F%E5%90%8C%E6%AD%A5%E4%B8%80%E4%B8%8B%EF%BC%81"><span class="toc-text">运行没反应？同步一下！</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%9C%A8GPU%E4%B8%8A%E7%9A%84%E8%AE%BE%E5%A4%87%E5%87%BD%E6%95%B0"><span class="toc-text">定义在GPU上的设备函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A3%B0%E6%98%8E%E4%B8%BA%E5%86%85%E8%81%94%E5%87%BD%E6%95%B0"><span class="toc-text">声明为内联函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%9C%A8-cpu-%E4%B8%8A%E7%9A%84%E4%B8%BB%E6%9C%BA%E5%87%BD%E6%95%B0"><span class="toc-text">定义在 cpu 上的主机函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8C%E6%97%B6%E5%AE%9A%E4%B9%89%E5%9C%A8-CPU-%E5%92%8C-GPU-%E4%B8%8A"><span class="toc-text">同时定义在 CPU 和 GPU 上</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%99constexpr%E5%8A%A0%E7%82%B9%E6%96%99"><span class="toc-text">给constexpr加点料</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%AE%B5%E7%BC%96%E8%AF%91"><span class="toc-text">多段编译</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E8%BF%87CMake%E8%AE%BE%E7%BD%AE%E6%9E%B6%E6%9E%84%E7%89%88%E6%9C%AC%E5%8F%B7"><span class="toc-text">通过CMake设置架构版本号</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%87%E5%AE%9A%E5%A4%9A%E4%B8%AA%E7%89%88%E6%9C%AC%E5%8F%B7"><span class="toc-text">指定多个版本号</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E6%9D%BF%E5%9D%97"><span class="toc-text">第一章：线程与板块</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E9%87%8D%E5%B0%96%E6%8B%AC%E5%8F%B7%E9%87%8C%E7%9A%84%E6%95%B0%E5%AD%97"><span class="toc-text">三重尖括号里的数字</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E7%BA%BF%E7%A8%8B%E7%BC%96%E5%8F%B7"><span class="toc-text">获取线程编号</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E7%BA%BF%E7%A8%8B%E6%95%B0%E9%87%8F"><span class="toc-text">获取线程数量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E4%B9%8B%E4%B8%8A%EF%BC%9A%E6%9D%BF%E5%9D%97"><span class="toc-text">线程之上：板块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E6%9D%BF%E5%9D%97%E7%BC%96%E5%8F%B7%E5%92%8C%E6%95%B0%E9%87%8F"><span class="toc-text">获取板块编号和数量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%90%86%E8%A7%A3%E7%BA%BF%E7%A8%8B%E7%AE%A1%E7%90%86"><span class="toc-text">理解线程管理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E3%80%81%E6%9D%BF%E5%9D%97%E4%B8%8E%E7%BD%91%E6%A0%BC%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84"><span class="toc-text">线程、板块与网格的层次结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8E%E5%B1%9E%E5%85%B3%E7%B3%BB"><span class="toc-text">从属关系</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E8%A6%81%E5%8F%98%E9%87%8F"><span class="toc-text">重要变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%83%E7%94%A8%E8%AF%AD%E6%B3%95"><span class="toc-text">调用语法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%80%9C%E6%89%81%E5%B9%B3%E5%8C%96%E2%80%9D%E7%90%86%E8%A7%A3"><span class="toc-text">“扁平化”理解</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%BE%E5%BD%A2%E7%90%86%E8%A7%A3"><span class="toc-text">图形理解</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E7%BB%B4%E7%9A%84%E6%9D%BF%E5%9D%97%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%BC%96%E5%8F%B7"><span class="toc-text">三维的板块和线程编号</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E7%BB%B4%EF%BC%9A"><span class="toc-text">二维：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%88%86%E4%B8%89%E7%BB%B4%E8%BF%99%E7%A7%8D%E7%BB%93%E6%9E%84%EF%BC%9F"><span class="toc-text">为什么要分三维这种结构？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%EF%BC%9A%E5%88%86%E7%A6%BB-device-%E5%87%BD%E6%95%B0%E7%9A%84%E5%A3%B0%E6%98%8E%E5%92%8C%E5%AE%9A%E4%B9%89"><span class="toc-text">补充：分离 device 函数的声明和定义</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%87%BA%E9%94%99%EF%BC%9A"><span class="toc-text">出错：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%EF%BC%9A"><span class="toc-text">解决：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%A4%E7%A7%8D%E5%BC%80%E5%90%AF%E6%96%B9%E5%BC%8F%EF%BC%9A%E5%85%A8%E5%B1%80%E6%9C%89%E6%95%88or%E4%BB%85%E9%92%88%E5%AF%B9%E5%8D%95%E4%B8%AA%E7%A8%8B%E5%BA%8F"><span class="toc-text">两种开启方式：全局有效or仅针对单个程序</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E4%B8%80%E6%AD%A5%EF%BC%9A%E6%A0%B8%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="toc-text">进一步：核函数调用核函数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="toc-text">第二章：内存管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%8E%E6%A0%B7%E4%BB%8E%E6%A0%B8%E5%87%BD%E6%95%B0%E8%BF%94%E5%9B%9E%E6%95%B0%E6%8D%AE%EF%BC%9F"><span class="toc-text">怎样从核函数返回数据？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%EF%BC%9A%E9%80%9A%E8%BF%87%E6%8C%87%E9%92%88%E4%BC%A0%E9%80%92"><span class="toc-text">试图解决：通过指针传递</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E8%BF%94%E5%9B%9E%E9%94%99%E8%AF%AF%E7%9A%84%E4%BB%A3%E7%A0%81"><span class="toc-text">分析返回错误的代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#helper-cuda-h%E5%B7%A5%E5%85%B7"><span class="toc-text">helper_cuda.h工具</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E5%A0%86%E4%B8%8A%E5%88%86%E9%85%8D%E8%AF%95%E8%AF%95%E5%91%A2%EF%BC%9F"><span class="toc-text">在堆上分配试试呢？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0%EF%BC%9AGPU-%E4%BD%BF%E7%94%A8%E7%8B%AC%E7%AB%8B%E7%9A%84%E6%98%BE%E5%AD%98%EF%BC%8C%E4%B8%8D%E8%83%BD%E8%AE%BF%E9%97%AE-CPU-%E5%86%85%E5%AD%98"><span class="toc-text">原因：GPU 使用独立的显存，不能访问 CPU 内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%8D%E4%B9%8B%E4%BA%A6%E7%84%B6%EF%BC%8CCPU-%E4%B9%9F%E4%B8%8D%E8%83%BD%E8%AE%BF%E9%97%AE-GPU-%E5%86%85%E5%AD%98%E5%9C%B0%E5%9D%80"><span class="toc-text">反之亦然，CPU 也不能访问 GPU 内存地址</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B7%A8-GPU-CPU-%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E6%8B%B7%E8%B4%9D%E6%95%B0%E6%8D%AE"><span class="toc-text">跨 GPU&#x2F;CPU 地址空间拷贝数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cudaMemcpy-%E4%BC%9A%E8%87%AA%E5%8A%A8%E5%90%8C%E6%AD%A5%EF%BC%81"><span class="toc-text">cudaMemcpy 会自动同步！</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E5%9C%B0%E5%9D%80%E6%8A%80%E6%9C%AF-%EF%BC%88Unified-Memory%EF%BC%89"><span class="toc-text">统一内存地址技术 （Unified Memory）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8C%BA%E5%88%86"><span class="toc-text">注意区分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9AGPU%E4%B8%8A%E7%9A%84%E6%95%B0%E7%BB%84"><span class="toc-text">第三章：GPU上的数组</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E9%85%8D%E4%B8%80%E4%B8%AA%E6%95%B0%E7%BB%84"><span class="toc-text">分配一个数组</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%B9%B6%E8%A1%8C%E8%B5%8B%E5%80%BC"><span class="toc-text">多个线程并行赋值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E6%8A%80%E5%B7%A7%EF%BC%9A%E7%BD%91%E6%A0%BC%E8%B7%A8%E6%AD%A5%E5%BE%AA%E7%8E%AF%EF%BC%88grid-stride-loop%EF%BC%89"><span class="toc-text">小技巧：网格跨步循环（grid-stride loop）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E7%BA%BF%E7%A8%8B%E5%88%B0%E6%9D%BF%E5%9D%97"><span class="toc-text">从线程到板块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%B9%E8%A7%92%E6%96%99%E9%9A%BE%E9%A2%98"><span class="toc-text">边角料难题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E8%BE%B9%E8%A7%92%E6%96%99%E9%9A%BE%E9%A2%98"><span class="toc-text">解决边角料难题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E6%A0%BC%E8%B7%A8%E6%AD%A5%E5%BE%AA%E7%8E%AF%EF%BC%9A%E5%BA%94%E7%94%A8%E4%BA%8E%E7%BA%BF%E7%A8%8B%E4%B8%8E%E6%9D%BF%E5%9D%97%E4%B8%80%E8%B5%B7%E7%9A%84%E6%83%85%E5%86%B5"><span class="toc-text">网格跨步循环：应用于线程与板块一起的情况</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B%E8%A7%A3%E9%87%8A%EF%BC%9A"><span class="toc-text">举例解释：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9AC-%E5%B0%81%E8%A3%85GPU%E4%B8%8A%E7%9A%84%E6%95%B0%E7%BB%84"><span class="toc-text">第四章：C++封装GPU上的数组</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#std-vector%E7%9A%84%E7%A7%98%E5%AF%86%EF%BC%9A%E7%AC%AC%E4%BA%8C%E6%A8%A1%E6%9D%BF%E5%8F%82%E6%95%B0"><span class="toc-text">std::vector的秘密：第二模板参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8A%BD%E8%B1%A1%E7%9A%84-std-allocator-%E6%8E%A5%E5%8F%A3"><span class="toc-text">抽象的 std::allocator 接口</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9B%E4%B8%80%E6%AD%A5%EF%BC%9A%E9%81%BF%E5%85%8D%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%BA0"><span class="toc-text">进一步：避免初始化为0</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9B%E4%B8%80%E6%AD%A5%EF%BC%9A%E6%A0%B8%E5%87%BD%E6%95%B0%E5%8F%AF%E4%BB%A5%E6%98%AF%E4%B8%80%E4%B8%AA%E6%A8%A1%E6%9D%BF%E5%87%BD%E6%95%B0"><span class="toc-text">进一步：核函数可以是一个模板函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9B%E4%B8%80%E6%AD%A5%EF%BC%9A%E6%A0%B8%E5%87%BD%E6%95%B0%E5%8F%AF%E4%BB%A5%E6%8E%A5%E5%8F%97%E5%87%BD%E5%AD%90-functor-%EF%BC%8C%E5%AE%9E%E7%8E%B0%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B"><span class="toc-text">进一步：核函数可以接受函子(functor)，实现函数式编程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9B%E4%B8%80%E6%AD%A5%EF%BC%9A%E5%87%BD%E5%AD%90%E5%8F%AF%E4%BB%A5%E6%98%AF-lambda-%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="toc-text">进一步：函子可以是 lambda 表达式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%8E%E6%A0%B7%E6%8D%95%E8%8E%B7%E5%A4%96%E9%83%A8%E5%8F%98%E9%87%8F%EF%BC%9F"><span class="toc-text">怎样捕获外部变量？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97"><span class="toc-text">第五章：数学运算</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E6%A1%88%E4%BE%8B%EF%BC%8C%E5%B9%B6%E8%A1%8C%E5%9C%B0%E6%B1%82-sin-%E5%80%BC"><span class="toc-text">经典案例，并行地求 sin 值</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E4%B8%80%E4%B8%8B%E6%97%B6%E9%97%B4"><span class="toc-text">测试一下时间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A8%8D%E5%BF%AB%EF%BC%8C%E4%BD%86%E4%B8%8D%E5%AE%8C%E5%85%A8%E7%B2%BE%E7%A1%AE%E7%9A%84-sinf"><span class="toc-text">稍快，但不完全精确的 __sinf</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E8%AF%91%E5%99%A8%E9%80%89%E9%A1%B9%EF%BC%9A-use-fast-math"><span class="toc-text">编译器选项：--use_fast_math</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SAXPY%EF%BC%88Scalar-A-times-X-Plus-Y%EF%BC%89"><span class="toc-text">SAXPY（Scalar A times X Plus Y）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9Athrust%E5%BA%93"><span class="toc-text">第六章：thrust库</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-CUDA-%E5%AE%98%E6%96%B9%E6%8F%90%E4%BE%9B%E7%9A%84-thrust-universal-vector"><span class="toc-text">使用 CUDA 官方提供的 thrust::universal_vector</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%88%86%E7%A6%BB%E7%9A%84-device-vector-%E5%92%8C-host-vector"><span class="toc-text">使用分离的 device_vector 和 host_vector</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-Thrust-%E6%A8%A1%E6%9D%BF%E5%87%BD%E6%95%B0%EF%BC%9Athrust-generate"><span class="toc-text">使用 Thrust 模板函数：thrust::generate</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-Thrust-%E6%A8%A1%E6%9D%BF%E5%87%BD%E6%95%B0%EF%BC%9Athrust-for-each"><span class="toc-text">使用 Thrust 模板函数：thrust::for_each</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Thrust-%E6%A8%A1%E6%9D%BF%E5%87%BD%E6%95%B0%E7%9A%84%E7%89%B9%E7%82%B9%EF%BC%9A%E8%87%AA%E5%8A%A8%E5%86%B3%E5%AE%9A-CPU-%E6%88%96-GPU-%E6%89%A7%E8%A1%8C"><span class="toc-text">Thrust 模板函数的特点：自动决定 CPU 或 GPU 执行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-counting-iterator-%E5%AE%9E%E7%8E%B0%E6%95%B4%E6%95%B0%E5%8C%BA%E9%97%B4%E5%BE%AA%E7%8E%AF"><span class="toc-text">使用 counting_iterator 实现整数区间循环</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-zip-iterator-%E5%90%88%E5%B9%B6%E5%A4%9A%E4%B8%AA%E8%BF%AD%E4%BB%A3%E5%99%A8"><span class="toc-text">使用 zip_iterator 合并多个迭代器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C"><span class="toc-text">第七章：原子操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E6%A1%88%E4%BE%8B%EF%BC%9A%E6%95%B0%E7%BB%84%E6%B1%82%E5%92%8C"><span class="toc-text">经典案例：数组求和</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C"><span class="toc-text">解决方案：使用原子操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#atomicAdd%EF%BC%9A%E4%BC%9A%E8%BF%94%E5%9B%9E%E6%97%A7%E5%80%BC%EF%BC%88%E5%88%92%E9%87%8D%E7%82%B9%EF%BC%81%EF%BC%89"><span class="toc-text">atomicAdd：会返回旧值（划重点！）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E5%AE%83%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C"><span class="toc-text">其它原子操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#atomicExch%EF%BC%9A%E5%8E%9F%E5%AD%90%E4%BA%A4%E6%8D%A2%E6%93%8D%E4%BD%9C%EF%BC%8C%E8%BF%94%E5%9B%9E%E6%97%A7%E5%80%BC"><span class="toc-text">atomicExch：原子交换操作，返回旧值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#atomicCAS%EF%BC%9A%E5%8E%9F%E5%AD%90%E6%AF%94%E8%BE%83%E4%B8%8E%E4%BA%A4%E6%8D%A2%E7%9A%84%E5%A6%99%E7%94%A8"><span class="toc-text">atomicCAS：原子比较与交换的妙用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%AD%90%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E7%9B%B8%E7%AD%89%EF%BC%8C%E7%9B%B8%E7%AD%89%E5%88%99%E5%86%99%E5%85%A5%E5%B9%B6%E8%BF%94%E5%9B%9E%E6%97%A7%E5%80%BC"><span class="toc-text">原子判断是否相等，相等则写入并返回旧值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C"><span class="toc-text">实现自定义原子操作</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%9A%84%E6%80%A7%E8%83%BD%E5%BD%B1%E5%93%8D"><span class="toc-text">原子操作的性能影响</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E6%84%8F%E5%A4%96%E5%9C%B0%E5%BE%88%E5%BF%AB%EF%BC%9F"><span class="toc-text">性能意外地很快？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%E7%BA%BF%E7%A8%8B%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%EF%BC%88TLS%EF%BC%89"><span class="toc-text">解决方案：线程局部变量（TLS）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E6%95%88%E6%9E%9C"><span class="toc-text">优化效果</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E6%9D%BF%E5%9D%97%E4%B8%8E%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="toc-text">第8章：板块与共享内存</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%8C%BA%E5%88%86%E5%87%BA%E6%9D%BF%E5%9D%97%E7%9A%84%E6%A6%82%E5%BF%B5%EF%BC%9F"><span class="toc-text">为什么需要区分出板块的概念？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SM%EF%BC%88Streaming-Multiprocessors%EF%BC%89%E4%B8%8E%E6%9D%BF%E5%9D%97%EF%BC%88block%EF%BC%89"><span class="toc-text">SM（Streaming Multiprocessors）与板块（block）</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/01/02/%E5%AE%9E%E4%B9%A0/sphinx%20%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" title="Sphinx使用指南"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./img/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2/8.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Sphinx使用指南"/></a><div class="content"><a class="title" href="/2025/01/02/%E5%AE%9E%E4%B9%A0/sphinx%20%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" title="Sphinx使用指南">Sphinx使用指南</a><time datetime="2025-01-02T07:04:32.643Z" title="更新于 2025-01-02 15:04:32">2025-01-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/20/C++/Cpp20%E5%8D%8F%E7%A8%8B/Cpp20%E5%8D%8F%E7%A8%8B%E5%85%A5%E9%97%A8/" title="C++协程入门"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./img/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2/3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="C++协程入门"/></a><div class="content"><a class="title" href="/2024/11/20/C++/Cpp20%E5%8D%8F%E7%A8%8B/Cpp20%E5%8D%8F%E7%A8%8B%E5%85%A5%E9%97%A8/" title="C++协程入门">C++协程入门</a><time datetime="2025-01-02T07:02:54.546Z" title="更新于 2025-01-02 15:02:54">2025-01-02</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/./img/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2/6.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2025 By Ming</div><div class="footer_custom_text">Hi, 欢迎你来！</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://vercel-c6qs1so68-mings-projects-7cb05430.vercel.app/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://vercel-c6qs1so68-mings-projects-7cb05430.vercel.app/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.textContent = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>function loadLivere () {
  if (typeof LivereTower === 'object') {
    window.LivereTower.init()
  }
  else {
    (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
    })(document, 'script');
  }
}

if ('Twikoo' === 'Livere' || !true) {
  if (true) btf.loadComment(document.getElementById('lv-container'), loadLivere)
  else loadLivere()
}
else {
  function loadOtherComment () {
    loadLivere()
  }
}</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://vercel-c6qs1so68-mings-projects-7cb05430.vercel.app/',
        region: '',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><div class="aplayer no-destroy" data-id="12875524711" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-volume="0.4" data-order="random" data-autoplay="true"> </div><script id="canvas_nest" defer="defer" color="97,255,145" opacity="0.7" zIndex="-1" count="88" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script>(() => {
  window.$crisp = [];
  window.CRISP_WEBSITE_ID = "b178ba69-5256-414b-adab-10306c2edf59";
  (function () {
    d = document;
    s = d.createElement("script");
    s.src = "https://client.crisp.chat/l.js";
    s.async = 1;
    d.getElementsByTagName("head")[0].appendChild(s);
  })();
  $crisp.push(["safe", true])

  const isChatBtn = true
  const isChatHideShow = true

  if (isChatBtn) {
    const open = () => {
      $crisp.push(["do", "chat:show"])
      $crisp.push(["do", "chat:open"])
    }

    const close = () => {
      $crisp.push(["do", "chat:hide"])
    }

    close()
    $crisp.push(["on", "chat:closed", function() {
      close()
    }])

    window.chatBtnFn = () => {
      $crisp.is("chat:visible") ? close() : open()
    }
  } else if (isChatHideShow) {
    window.chatBtn = {
      hide: () => {
        $crisp.push(["do", "chat:hide"])
      },
      show: () => {
        $crisp.push(["do", "chat:show"])
      }
    }
  }
})()</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"]):not([href="/music/"]):not([href="/no-pjax/"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>